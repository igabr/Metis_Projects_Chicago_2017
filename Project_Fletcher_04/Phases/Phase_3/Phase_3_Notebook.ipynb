{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run helper_functions.py\n",
    "%run tweepy_wrapper.py\n",
    "%run s3.py\n",
    "%run mongo.py\n",
    "%run df_functions.py\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words(\"english\")+[\"rt\", \"via\",\"-¬ª\",\"--¬ª\",\"--\",\"---\",\"-->\",\"<--\",\"->\",\"<-\",\"¬´--\",\"¬´\",\"¬´-\",\"¬ª\",\"¬´¬ª\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Obtain my tweets!\n",
    "\n",
    "I will obtain my entire tweet history! Note: For 2nd degree potential followers, I only extract 200 of their most recent tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gabr_tweets = extract_users_tweets(\"gabr_ibrahim\", 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a dictionary from my tweets\n",
    "\n",
    "This dictionary will have the same structure as our already collected 2nd degree followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gabr_dict = dict()\n",
    "gabr_dict['gabr_ibrahim'] = {\"content\" : [], \"hashtags\" : [], \"retweet_count\": [], \"favorite_count\": []}\n",
    "\n",
    "for tweet in gabr_tweets:\n",
    "    text = extract_text(tweet)\n",
    "    hashtags = extract_hashtags(tweet)\n",
    "    rts = tweet.retweet_count\n",
    "    fav = tweet.favorite_count\n",
    "    \n",
    "    gabr_dict['gabr_ibrahim']['content'].append(text)\n",
    "    gabr_dict['gabr_ibrahim']['hashtags'].extend(hashtags)\n",
    "    gabr_dict['gabr_ibrahim'][\"retweet_count\"].append(rts)\n",
    "    gabr_dict['gabr_ibrahim'][\"favorite_count\"].append(fav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a dataframe from my tweets\n",
    "\n",
    "We will now turn this dictionary into a dataframe - I do this as it allows me to utilise pandas in cleaning the content of my tweets!\n",
    "\n",
    "After the cleaning on the 'content' column, I will convert the dataframe back into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gabr_tweets_df = pd.DataFrame.from_dict(gabr_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>content</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gabr_ibrahim</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[RT @UChicagoCAPP: Great turnout today! Hope y...</td>\n",
       "      <td>[5, 1, 1065, 1, 0, 11, 27, 1407, 728, 1107, 0,...</td>\n",
       "      <td>[opendata, NLP, spaCy, Metis, TopicModelling, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 favorite_count  \\\n",
       "gabr_ibrahim  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                        content  \\\n",
       "gabr_ibrahim  [RT @UChicagoCAPP: Great turnout today! Hope y...   \n",
       "\n",
       "                                                  retweet_count  \\\n",
       "gabr_ibrahim  [5, 1, 1065, 1, 0, 11, 27, 1407, 728, 1107, 0,...   \n",
       "\n",
       "                                                       hashtags  \n",
       "gabr_ibrahim  [opendata, NLP, spaCy, Metis, TopicModelling, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabr_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets = filtration(gabr_tweets_df, \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets = dataframe_to_dict(clean_gabr_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gabr_ibrahim': {'content': ['great turnout today hope able join us slides available link video webinar coming soon',\n",
       "    'ms capp student talks challenges value time',\n",
       "    'good news steve bannon gone bad news replaced sentient swastika right arm permanently',\n",
       "    'byyyeeeee',\n",
       "    'late night could possibly better',\n",
       "    'millennials killed confederate monument',\n",
       "    'find friends speakers around add yourself directory',\n",
       "    'in gop led homeland security committee declare charlottesville attack act domestic terrorism',\n",
       "    \"republicans extremely opposed erasing history unless it's named obama insures million americans\",\n",
       "    'mean ok',\n",
       "    'this',\n",
       "    'idea nazis people oppose nazis somehow equatable batshit fucking crazy shit i ever',\n",
       "    'god grant serenity accept get grant, courage write anyway, wisdom know',\n",
       "    'seriously though work castle',\n",
       "    'sure, cancer aggressive chemotherapy also aggressive aggression sides',\n",
       "    \"problem another's solution; solution problem unknown\",\n",
       "    'big oshit',\n",
       "    'j hus see keeps vibin late night coding session',\n",
       "    'note expensive network traffic explains shuffles bad data management important',\n",
       "    'humanized latency metrics useful remember you, uh, ever use network',\n",
       "    'academic datasets usually perfectly balanced real world datasets messy, unbalanced incomplete',\n",
       "    'clip made day',\n",
       "    'team hiring folks search, nlp, machine learning backgrounds; get touch know anyone',\n",
       "    'must read get extra dose imposter syndrome reading math heavy ml papers',\n",
       "    'bahahahahaa',\n",
       "    'he insult cabinet, party congress he insult presidents war heroes nazis putin?',\n",
       "    'violence, chaos, apparent loss life charlottesville fault sides racists',\n",
       "    'wow president cannot condemn white supremacy wow nobody surprised white supremacists',\n",
       "    'trump afraid say it, radical islamic terror white supremacy? nope ü§î',\n",
       "    'join us hear jens ludwig discuss trends public policy',\n",
       "    'customize start up blog post',\n",
       "    \"understand people do want read research papers, it's non issue it's blatant\",\n",
       "    'every time hit paywall, blows mind taxpayers are constantly fury pay research',\n",
       "    'you constant source inspiration thanks great role model i getting book asap',\n",
       "    '',\n",
       "    'aws s3 walkthrough, setup use harness power cloud computing blog post',\n",
       "    'ibm system claimed accuracy w75m images hrs previous record microsoft, days',\n",
       "    '',\n",
       "    '',\n",
       "    'flask app gross wait bootstrapping yaaaaaasss fully decked professional looking app mins',\n",
       "    'interviewing phd program, professor interviewing said focus, \"technology affecting politics\"',\n",
       "    'cores ram happy birthday',\n",
       "    'exceptional work metis sr data scientist',\n",
       "    'libraries are books almost public space left do like wallets',\n",
       "    'enough dongles',\n",
       "    'learned integrate ec2 s3 bless blog post tutorial coming soon',\n",
       "    'avoid overfitting',\n",
       "    'af researchers forced ghost bae ai creates language',\n",
       "    'replace multiplication gradient descent calls regulation ai see',\n",
       "    'bitcoin fork crypto market madness next hours',\n",
       "    \"know that's meant,\",\n",
       "    'scaramucci, barely knewcci',\n",
       "    '',\n",
       "    \"nah it's pretty funny\",\n",
       "    'soon therell enough former wh staffers entire season dancing stars',\n",
       "    '',\n",
       "    'bahahahahahahaha',\n",
       "    'shortest serving comms director history? along cos',\n",
       "    'best programming skills knowing walk away while oscar godson',\n",
       "    \"it's amazing it's recommended use version pickle\",\n",
       "    'standard pickle library great do use bs4 objects, leads',\n",
       "    'thanks renee',\n",
       "    \"you tidy data me i'm going nest dictionaries levels deep\",\n",
       "    'aws n_jobs= 1',\n",
       "    \"discovered portillo's today cake shake changed lifechicago\",\n",
       "    \"simpson's paradox explained gif\",\n",
       "    'really love power awsmwhahahahaall cores',\n",
       "    'reporter live real data scientist tell us sexy job me maniacally worked locally,',\n",
       "    '',\n",
       "    'frustrated white house would walk see jefferson read this hope',\n",
       "    'even motherfucking orrin hatch thinks bullshit orrin hatch',\n",
       "    'making aliases bash light speed workflow going want read this',\n",
       "    'prime factorization complexity blog post',\n",
       "    'project complete blog here',\n",
       "    \"also learned r it's amazing resource promise do work them\",\n",
       "    '',\n",
       "    'walkthrough set jupyter notebookshow use aliasing aws',\n",
       "    \"deborah sql jockey join limit mikey statistician result, what's n?\",\n",
       "    \"clear i'm asking whether true\",\n",
       "    'better always use stratifiedkfold kfold? shuffle=true cases stratified would better bias variance cv?',\n",
       "    '',\n",
       "    '',\n",
       "    'scientific process cool hard shit shit actually going work',\n",
       "    'yyyaaaaassss',\n",
       "    'ü§î',\n",
       "    'tired worrying algorithms wired removing algorithms curriculum inspired algorithms',\n",
       "    '\"you face classic prisoners dilemma do?\" \"i pardon guy myself also youre fired\"',\n",
       "    'tired subjective nature tech hiring terrify us wired use algorithms tech hiring terrify us',\n",
       "    'do know, etl short part data science one wants do',\n",
       "    'gridsearchcv takes worries away',\n",
       "    'mastercard cisco join',\n",
       "    'oh wow could really end political career',\n",
       "    '\"clean csv pre prepared meal kit\" amazing analogy ‚ú®',\n",
       "    'welcome meetup event',\n",
       "    'tired arguing whether data wired arguing whether we inspired arguing',\n",
       "    \"week scraping cleaningit's finally dataframeanalysis tomorrow firstsleep\",\n",
       "    'stop telling lies?',\n",
       "    'major progress project time sleep',\n",
       "    'breaking mcconnell concedes drive erase, replace obama health law failed; plans repeal vote, delay substitute',\n",
       "    'without try except clauses, do think web scraping would ever possible least way allows storage',\n",
       "    'bless any method',\n",
       "    \"twice much twitter good me i'm running\",\n",
       "    \"got back tonight pro tip last season, get hbo's free month trial online live streaming that's episodes\",\n",
       "    'dad, borrow computer? forgot magic word sudo ok then',\n",
       "    'britainwonderful',\n",
       "    'incredible inspiring read',\n",
       "    '',\n",
       "    \"reason academia cutthroat there's little stake\",\n",
       "    'wow incredible quote regarding government data',\n",
       "    'meanshift clustering described people wandering around foggy football field',\n",
       "    'event hosted event link',\n",
       "    'time flies you fun got home',\n",
       "    'one left office',\n",
       "    'multiprocessing library changed life forever',\n",
       "    'aliasing git commands greatest thing ever  totally gonna blog',\n",
       "    'works pandas dataframes',\n",
       "    \"i'm struggling finding interesting question\",\n",
       "    'good ideaslinks cool datasets would perfect linear regression analysis python? looking fun project',\n",
       "    'project completed check details blog',\n",
       "    'blistering accurate see us',\n",
       "    \"me, taking another toothpick i'm concerned sample size small farmer's market vendor please stop\",\n",
       "    'shameless self promotion personal website running check out',\n",
       "    'got around making personal website check first blog post ever',\n",
       "    'largest product series',\n",
       "    'binary search implementation',\n",
       "    'spell?',\n",
       "    'pair programming',\n",
       "    'introduction',\n",
       "    '',\n",
       "    'mi5 sponsor data science challenge assist spotting terrorism',\n",
       "    'command line tip day use filename` clear content file without deleting it',\n",
       "    \"legal technology, lawyers love say programmers need them think it's way around\",\n",
       "    'really work i learned great deal made fantastic',\n",
       "    'beast woman',\n",
       "    'differentially private gans generate fake clinical trial data train ml algorithm without sacrificing privacy',\n",
       "    \"breaking illinois house overrides governor's budget package veto enact first spending plan since\",\n",
       "    '',\n",
       "    '',\n",
       "    '',\n",
       "    \"best non technical pydata talk seen highlights many issues struggle with it's must watch\",\n",
       "    '',\n",
       "    'happy birthday america ü§ó',\n",
       "    'confirmationwhat way kick',\n",
       "    'ah shit',\n",
       "    'breaking new jersey gop gov chris christie signs budget deal following impasse led government shutdown',\n",
       "    'ny benefited lot great teachers, smart diverse group students',\n",
       "    'new senate quietly pushing subtle change health care bill gut medicaid, allow states',\n",
       "    'focus group could avoided focus group women',\n",
       "    'companies hired coding bootcamp graduate, said would',\n",
       "    'argue research do like',\n",
       "    '',\n",
       "    '',\n",
       "    'great high level overview neural networks easy read digestible',\n",
       "    \"blockchain potential spur new era financial inclusion here's how\",\n",
       "    'poll finds britons want keep eu citizenship',\n",
       "    'wrote python script check stashmetrics check feedback appreciated first attempt',\n",
       "    'sent prison software programs secret algorithms',\n",
       "    'rightly viewed, possesses truth supreme beauty russell',\n",
       "    'distill concept basics like explaining yr old helps solidify',\n",
       "    'dont fuck postdocs',\n",
       "    'still think nyc better?',\n",
       "    'ü§îü§î get bagel?',\n",
       "    'beats nyc smoked meat day',\n",
       "    'drake ferrell got rolling bro',\n",
       "    'alma mater',\n",
       "    'remember called every datacs curriculum include ethics security curriculum this?',\n",
       "    'def selfcore true',\n",
       "    \"mock week really makes miss home bless vpn's bbc iplayer\",\n",
       "    'key developer milestone you written enough code able reference code researching',\n",
       "    'st viateur bagels',\n",
       "    '',\n",
       "    'mount royal  view top incredible la banquise poutine st denisst laurent',\n",
       "    \"atleast it's stata\",\n",
       "    'love',\n",
       "    'preach go grad school major problem apparent',\n",
       "    'really interesting analysis python imports files files github cc',\n",
       "    'intro blockchain goldman sachs absolutely incredible presentation ux mind blowing',\n",
       "    'interactive regex crossword help teach regex bless internet',\n",
       "    '',\n",
       "    'forgotten front finally here thanks everyone interest project cambridge discount',\n",
       "    'i never seen one sentence headline contradict',\n",
       "    'succinct overview bayes theorem come across',\n",
       "    'h 1b visas big issue go',\n",
       "    '',\n",
       "    'would love join slack channel',\n",
       "    'jaro winkler good compare us addresses bc penalizes edits closer end str city, st blocking key',\n",
       "    'passive aggressive logging',\n",
       "    'eid mubarak students, staff alumni celebrating today',\n",
       "    'uk parliament hit cyber attack, says liberal democrat peer lord rennard',\n",
       "    'keeping distributions relationships straight mind thank you',\n",
       "    'were hiring project coordinator join ethics governance project',\n",
       "    '',\n",
       "    \"incredibly important today's information age\",\n",
       "    'great read',\n",
       "    'fantastic read highly relevant interested finance',\n",
       "    'friends join us data science social',\n",
       "    \"periodic reminder are following many women data science, it's bc are twitter\",\n",
       "    'thank enriching coding life deserve award always dread looking plot',\n",
       "    'ugh fish worst',\n",
       "    '',\n",
       "    'daughter playing student',\n",
       "    '',\n",
       "    'responding reviewer comments',\n",
       "    'foucault education',\n",
       "    'one idols liked tweet ü§ó thank incredible role model us',\n",
       "    'strip mall starbucks, theory contends, ever gone war another',\n",
       "    'powerful paragraphs always remember intricacies data',\n",
       "    \"yyyaaaaasss i'm budding data scientist polisci background\",\n",
       "    'bash makes happy',\n",
       "    'i using markdown years never took time learn properly discovered create block quotes ',\n",
       "    'well written',\n",
       "    'chicago made public ranking arrestees risk, predicted algorithm',\n",
       "    '\"ethereum internet be\"',\n",
       "    'past self do worry general solution, ship something now current self fuck',\n",
       "    \"it's minseth\",\n",
       "    \"i'm going sleep like baby \",\n",
       "    \"i'm officially losing mind \",\n",
       "    \"i'm screaming\",\n",
       "    '',\n",
       "    'wow good labour stronger good brutal brexit rejected good next generation realized stakes spoke up',\n",
       "    'interesting watch republican senators challenge james comey seven minutes donald trump',\n",
       "    'breaking british news media say prime minister theresa may resign election setback',\n",
       "    'breaking british media report party hold majority surprising conservative fall, hung parliament',\n",
       "    \"another reminder campaign manager great progressive hero barack obama ran theresa may's campaign\",\n",
       "    \"in it's officially hung parliament uk election party get overall majority\",\n",
       "    \"breaking uk pm may's conservatives longer able win outright majority parliament seats declared\",\n",
       "    'done thanks looking forward seeing odsc team again',\n",
       "    'pols open sure get vote time complacency',\n",
       "    'hey odsc team idea expect free tickets upcoming odsc conference eagerly checking mail daily',\n",
       "    'gets mention apple keynote',\n",
       "    \"wait whatit's like seconds\",\n",
       "    'focus discrete math, stop looking ticker',\n",
       "    'in seven members public killed london attack, metropolitan police commissioner says',\n",
       "    'london terror attack police shoot dead three suspects rampage kills six',\n",
       "    'things have decades software experience partner child hobbies coding things do have',\n",
       "    'jeremy corbyn says labour suspend national campaigning evening following',\n",
       "    'final scene leaves many questions feels ‚ò∫Ô∏è',\n",
       "    'hell hath fury like jupyter notebook many print statements',\n",
       "    'pyspark cluster keeps crashing databases assignment impossible use built functionality spark',\n",
       "    'lie pillow week go tons done forges warriors pits hell grad school ü§ï',\n",
       "    'story four tweets hope understand muslim feels burden us crimes others',\n",
       "    'zbigniew brzezinski, former national security adviser long time wise man world affairs, dies rip',\n",
       "    'scientifically literate empower know someone else full shit',\n",
       "    '',\n",
       "    \"challenging jared negotiate israel palestine peace plan he's indicted\",\n",
       "    'brilliant primer ethereum cryptocurrency markets changing',\n",
       "    'even exposure',\n",
       "    '',\n",
       "    'brit expats us sending postal vote, add stamp free post valid uk',\n",
       "    '',\n",
       "    'graduate student unionisation demonstration',\n",
       "    \"pm'd\",\n",
       "    'ever invest yourself?',\n",
       "    '',\n",
       "    'truly appreciate modern machine learning age put away childish things age calculus, c++ age nips poster age',\n",
       "    'coinbase kraken excellent platforms wo answering second question, penny',\n",
       "    'absolutely incredible however, apr close cost prohibitive',\n",
       "    'theresa may suspends election campaigning following manchester explosion',\n",
       "    'theresa may says thoughts victims families affected treated police',\n",
       "    'updated police report multiple deaths following apparent blast ariana grande concert manchester',\n",
       "    'manchester arena police confirm fatalities explosion ariana grande concert ‚Äì live',\n",
       "    'police say fatalities incident ariana grande concert',\n",
       "    'matter time',\n",
       "    'especially look tweet eth now',\n",
       "    'companies pic exact',\n",
       "    'new eea members',\n",
       "    'words must breaking news',\n",
       "    'breached',\n",
       "    'incredible read',\n",
       "    'breaking senate intelligence committee says former fbi director comey agrees testify open session statement',\n",
       "    'it return one month ',\n",
       "    'tears everywhere',\n",
       "    'okthis insane do know myself returns',\n",
       "    'aaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhh happening ',\n",
       "    \"it's hits i'm gonna straight cry\",\n",
       "    'serious crowd opening',\n",
       "    'breathing',\n",
       "    'fred wilson eth market cap surpass bitcoin market cap end year ',\n",
       "    'eth adoption',\n",
       "    'look list companies interested eth',\n",
       "    'too time alive',\n",
       "    'never understand art',\n",
       "    'price rise making dance dont dance',\n",
       "    'wwwwhhhhaaaaaaaaaaaaa focusing work tonight',\n",
       "    'happening yaaaaasssss im screaammiinngg',\n",
       "    'its you, its omission oxford comma',\n",
       "    'do make teaching mistakes create democratizing spaces discovery learning critical pedagogy',\n",
       "    '',\n",
       "    'stuck contraposition dayand boom youtube vidim roll today donating khan academy websites now',\n",
       "    'bad funny',\n",
       "    'series videos better mental health grades all',\n",
       "    'yet khan academy knocking outta park explanation proof induction syllabi grad school',\n",
       "    'love machine learning much next data nerd also',\n",
       "    'proof induction textbook youtube videos need brilliant educators online',\n",
       "    '',\n",
       "    '',\n",
       "    'no open positions deep learning experts, according gartner no deep learning experts, according',\n",
       "    'javier valdez, award winning journalist killed mexico, targeted reporting, writes',\n",
       "    'landmark european court case could curtail freedoms british dual nationals',\n",
       "    'polls undercount centrists, populists',\n",
       "    'ethereum gets avoid bad press',\n",
       "    'ransomware attacks devastating however, question mind isbitcoin? pfftat least pull right get ethereum',\n",
       "    'hour midterm finally understand big notation bless khan academy',\n",
       "    \"reading shirt calm and conda install daddy, what's conda? know\",\n",
       "    'breaking acting fbi director andrew mccabe tells senate panel update white house russia investigation',\n",
       "    'breaking acting fbi director calls trump russia investigation significant, contradicting white house claim',\n",
       "    '',\n",
       "    'amazing even lavrov shocked',\n",
       "    'printsortedlistsetlst 2 find highest val list sometimes, marvel elegant be',\n",
       "    'political scientists do time shit',\n",
       "    \"george w bush's ethics lawyer\",\n",
       "    \"wh made calculation however bad looks, it's better letting comey continue supervise\",\n",
       "    'data news',\n",
       "    'co authoring',\n",
       "    'listening morning like idea hackathons focus cleaning prepping',\n",
       "    'lunch order',\n",
       "    'trump delete webpage case court, ca delete bigotry behind',\n",
       "    'traced saga syrian family order resettled us vetting process steps total',\n",
       "    'heritage gets shoutout discrete math textbook',\n",
       "    'got email today bots becoming sophisticated knew could find casual encounters',\n",
       "    'best breakdown svd i ever seen incredible profs',\n",
       "    'matrix diagonalization beautiful',\n",
       "    'pyotr tchaikovsky‚Äîcomposer \"the nutcracker\"‚Äîwas born',\n",
       "    'coding, tsa precheck best gift me',\n",
       "    'why?',\n",
       "    'highly recommend article people entering data science employers need help navigating',\n",
       "    \"colbert calls trump cock gobbler fcc investigation, news agency's blast py it's cool?\",\n",
       "    'fantastic read',\n",
       "    'breaking russia backed deal set zones syria designed reduce violence comes effect',\n",
       "    'breaking texas officer charged murder shooting black car leaving party, arrest warrant issued',\n",
       "    'does know anything cancer smart application antibodies',\n",
       "    'mind blowing applications healthcare talk google x labs',\n",
       "    'tutorial day great start',\n",
       "    '',\n",
       "    'how??',\n",
       "    'need contain emotions public then',\n",
       "    \"am fact, i'm modelling ml algo's right now\",\n",
       "    'think you enjoy presentation today',\n",
       "    'calls americans focus global refugee crisis amen',\n",
       "    'talk uhcr using data',\n",
       "    '',\n",
       "    'udemy flesh phenomenal explanations usual',\n",
       "    'conference fantastic mandatory blast',\n",
       "    '',\n",
       "    'thank free ticket future event knowledge',\n",
       "    'great talk loved every second yes, absolutely hilarious',\n",
       "    'learning news things every talk',\n",
       "    'yay thank you',\n",
       "    'best slide today far',\n",
       "    'watching loyal datasci subjects one datasci idols',\n",
       "    'interesting talk quantum computing amazing could impact cryptography',\n",
       "    'im excitteeedd',\n",
       "    'announcement juliadb',\n",
       "    'native linear algebra data type julia',\n",
       "    \"julia unicode support that's right latex syntax assigned variable\",\n",
       "    'ethereum cracked yaaaaasssssss',\n",
       "    'pumped presentation i heard much power time see action',\n",
       "    'free datasci goodies absolutely amazing community',\n",
       "    'congrats scikit learn winning award outstanding open source project much deserved cc',\n",
       "    \"say say science'\",\n",
       "    'yuge crowd keynote tom davenport following',\n",
       "    'skills',\n",
       "    'people data science days',\n",
       "    'wondering use help make broad impacts? stop table career',\n",
       "    'emergency meetings held buckingham palace',\n",
       "    'never sure you relationship qualitative researcher everything significant',\n",
       "    'information leakage',\n",
       "    'best me slide i ever seen almost reminds osi modelpacket encapsulation',\n",
       "    'learning code greatest gift ever given',\n",
       "    'rstudio',\n",
       "    'book signing coming',\n",
       "    \"images' data sharing\",\n",
       "    'plugging gaps self cleaning training sklearn »ôodsc realizing much still',\n",
       "    'analysis assumes clean data world rarely delivers it',\n",
       "    'preach',\n",
       "    'made exciting eat',\n",
       "    'excited full day scikit learn boston material',\n",
       "    'east',\n",
       "    'here',\n",
       "    'older man leans guy, really man sister?',\n",
       "    'period silence guests seated near couple burger better lit',\n",
       "    'never tell mom me? ashamed me tell her time w',\n",
       "    \"trying keep options open fuck mean that's sister, respectful?\",\n",
       "    'pours water food bounces craziest burger experience i ever had',\n",
       "    'yay see there',\n",
       "    'too presenting?',\n",
       "    'period silence guests seated near couple burger better lit',\n",
       "    'never tell mom me? ashamed me tell her time w guy beach?',\n",
       "    \"trying keep options open fuck mean that's sister, respectful?\",\n",
       "    'boston burger co couple next arguing whether frnds morewhat mean looking elsewhere?',\n",
       "    'got pass thank much excited tomorrow',\n",
       "    'do get bored reminding people labour changed britain',\n",
       "    'play three acts',\n",
       "    'hands best fried chicken i life bless chitown honneeeyy bbuutteerr',\n",
       "    'serious employer field ask github account need encourage',\n",
       "    \"what's text? i'd interested giving read i'm ml course right now need knowledge get\",\n",
       "    'writing book?',\n",
       "    \"put logo syllabus first time it's clear, psyched job\",\n",
       "    '',\n",
       "    \"me lin alg hw stop looking price ethereum' mins later7450coin around room show money\",\n",
       "    \"brain food playlist spotify tends get zone i'm also looking suggestions\",\n",
       "    'quote day american journalist edward r murrow',\n",
       "    \"won won won won that? national front, macron's team? no, pollsters\",\n",
       "    'time download',\n",
       "    'former president barack obama live noon et c span',\n",
       "    'doors open former president speech logan center',\n",
       "    'trump fired surgeon general called gun violence public health issue',\n",
       "    'whole days metric stupid you counting',\n",
       "    'worlds beautiful mathematical equation',\n",
       "    'sine game',\n",
       "    'pier review',\n",
       "    'research funding explained',\n",
       "    \"forced guess i'd say le pen beats polls, that's bc terror attack otherwise might good\",\n",
       "    'breaking champs elysees paris closed authorities telling people avoid area',\n",
       "    \"team released ipython it's python only completion looks awesome\",\n",
       "    \"details ipython team's rationale behind dropping python support blog post last year\",\n",
       "    'would incredible let know find resource',\n",
       "    'ordinary people, extraordinary things',\n",
       "    '',\n",
       "    'needed scale ml algo intricacies next customer walks door leaving money table',\n",
       "    '',\n",
       "    'next phase ml careful construction models fit nuances customer shelf lasso, rf, cnn',\n",
       "    'tongue in cheek math slide concerning traditional ml pipeline optimisation business',\n",
       "    'human impression advertising completed ms need able make decisions faster',\n",
       "    'prof sanjog misra taking stage ml making',\n",
       "    '',\n",
       "    'aparna pandey ca ml summit without talking deep learning increase literature around it',\n",
       "    'aparna pandey fear missing comes big companies machine learning',\n",
       "    'entire landscape business',\n",
       "    \"ai hottest technolgies right it's also important remember it's new technology change\",\n",
       "    'aparna',\n",
       "    'assisting human element',\n",
       "    'apama pandey uptake use ml better facilitate use resources large machine repairs replacing human element',\n",
       "    'szabolcs paldy empathise technology b2c applications b2c concerned solving needs indiv level',\n",
       "    'promus ventures working sentiment analysis unique data points minimum train algo',\n",
       "    'data trace back physical address deploy direct mail advertising based items dropped online shopping cart',\n",
       "    'job morris rise interactive technology monitor someone abandons online shopping cart, take ipmeta',\n",
       "    'panel session kicking now impressive lineup',\n",
       "    'sign available now free storage access spark cluster',\n",
       "    'first venn diagram',\n",
       "    'time spent data pre processingwhile may boring, crucial step',\n",
       "    'watson committed apache spark',\n",
       "    'lead product manager ibm watson stage',\n",
       "    'i live tweeting chicago booth machine learning summit',\n",
       "    'breaking fox news preparing cut ties bill oilly wake sexual harassment allegations',\n",
       "    'early voting numbers do matter early voting numbers do matter early voting numbers do matter early voting',\n",
       "    'trump says wants best people migrate america first, visas workers middling skills',\n",
       "    'thought could life quarterdatabases, ml proposal lin alg assignments due mondaycapp',\n",
       "    \"kendrick's dna stepping away ml hw simply contemplate bars dropped\",\n",
       "    'everything makes cry best ai algos used solve painfully world problems join',\n",
       "    'read this great article work matters esp communicating modern',\n",
       "    'nightmare',\n",
       "    \"i'm imagining apsa attendees calling dr looking meaningfully grad students,\",\n",
       "    'night long',\n",
       "    'student constantly interacts students diff disciplines, comes much',\n",
       "    \"need playlist suggestions late nightproductive coding far, i found chainsmokers spotify's brainfood\",\n",
       "    \"let's get nitty gritty feature selection methods model evaluation also\",\n",
       "    'look airspace around north korea',\n",
       "    \"it's true get waves incredibly cathartic emotions clean, sort, split model ml algo's msc me\",\n",
       "    'pepsi did work?',\n",
       "    'people, faced problem, think, know, i use statistics ¬± problems',\n",
       "    'people studying deterministic progress mocks person studying probabilistic process making progress',\n",
       "    'soon we war iraq, afghanistan, syria, north korea?',\n",
       "    '',\n",
       "    'solemnly swear never underappreciate lambda functions',\n",
       "    'trump wont post wh visitor logs, citing \"security risks,\" says move save taxpayers one',\n",
       "    'need design ml pipeline tells eat designing ml pipelines',\n",
       "    'l shaped scatter plotsapparently people income debt ratioshmmmmore data cleaning',\n",
       "    'reminder attorney general united states committed perjury confirmation congress',\n",
       "    'oh wow professor slymany numbers do make sensesimply imputing isnt going workim data janitor',\n",
       "    'imputationimputation everywherebins everywhereso many numbers',\n",
       "    \"ml hw data cleaning, eda, feature cleaning blown away people's debt ratio's wondering it's data entry error\",\n",
       "    'might time head back canada',\n",
       "    \"today's blog discusses pay close attention identity construct\",\n",
       "    \"spent two years collecting data ran anova p=0052 it's nice knowing everyone\",\n",
       "    \"i'm love feature selection method's scikit learn\",\n",
       "    'amazing definition',\n",
       "    'ml algos tons algos algo cmplx sys lose algo ppl do theyre called academics',\n",
       "    'data science conference bingo',\n",
       "    'back envelope proof ‚àõ2 irrational',\n",
       "    'make sure kids see graph',\n",
       "    'long read origin deep learning really gorgeous mathematicalintuitive explanations',\n",
       "    'data scientist like owning car taking numerical linear algebra like learning rebuild engine',\n",
       "    'schumpeter university chicago worries lack competition',\n",
       "    'favorite data viz week',\n",
       "    'trump policy reversals today fed hiring freeze, nato exim bank, labeling china currency',\n",
       "    '',\n",
       "    'lol, alright fine laughed',\n",
       "    '\"should learn deep learning\" new \"should get phd\"',\n",
       "    'plein air favourite place start day breakfast linear algebra',\n",
       "    'ctu guy legacy say tell tweak parameters s q l speed computer?',\n",
       "    \"here's quote\",\n",
       "    'hope post online would valuable resource learn from',\n",
       "    \"i never get past powerful for loops are looping classification algo's cross validating breeze\",\n",
       "    'us intelligence community consensus russia foreknowledge syrian chemical attack  us official',\n",
       "    'alabama governor resigns scandal leads criminal charges',\n",
       "    'alabama governor resigns sex scandal top aide',\n",
       "    'congrats new director institute',\n",
       "    \"young thug's lifestyle serving motivation get sql assignment basement\",\n",
       "    'wins twitter today hands down',\n",
       "    'spicer recognizes icc?',\n",
       "    'visualise space right?',\n",
       "    'yikes getting better reading personal diary getting better linalg',\n",
       "    \"insightful moments strang's book wave emotions getting better linalg reading equivalent personal diary?\",\n",
       "    'suspect ui designer might lied cv',\n",
       "    'overheard really want shut airport syria, let delta gate agents run it',\n",
       "    'passion fruit machine learning',\n",
       "    'let drinking machine learning begin also someone remind turn aws gpu instance sleep',\n",
       "    'breaking russian military says help syria strengthen air defenses us strike',\n",
       "    'breaking swedish prime minister stefan lofven says everything indicates truck crashing department store terror attack',\n",
       "    \"trump's decision strike syria carries considerable risks look could mean\",\n",
       "    '',\n",
       "    'please remember republicans applauding strikes caring poor syrians fine supporting',\n",
       "    'beautiful pictures? fuck msnbc',\n",
       "    'serious question trump administration authority, credibility, clarity thought answer',\n",
       "    'boy, did take long discover clinton, bush, obama learned air strikes easy way look tough wo',\n",
       "    'middle east exploding trump response reduce state dept budget cut foreign aid close borders expand military',\n",
       "    \"i'm sorry, makes fucking sense whatsoever\",\n",
       "    'breaking homs governor tells us missile strikes syrian base result deaths',\n",
       "    'look',\n",
       "    'could kill emotional undergrad hutchinson feel bro hurting too',\n",
       "    'wo relational algebra homework conform flawless logic?',\n",
       "    'friday, joined universities filing amicus brief opposing revised executive order',\n",
       "    \"singing mario's love you machine leaning homework\",\n",
       "    'wife left note day suppose failed explaining living',\n",
       "    \"data pre processing ensuring underlying assumptions met order ml algo's work properly\",\n",
       "    'watching api request go like',\n",
       "    \"you new deep learning, encouraged part need learn learnable nobody knows all it's\",\n",
       "    'finally cracked census bureau api',\n",
       "    '',\n",
       "    'listening tswift ml polsky',\n",
       "    'know mike pence punches penis every night bad bad thoughts go back hell',\n",
       "    'breaking us judge approves settlement trump pay million trump university lawsuits, ending years litigation',\n",
       "    'cool crushing it',\n",
       "    \"drake's got zone late night ml\",\n",
       "    \"current administration compared really it's like animal farm freddy got fingered\",\n",
       "    'us applications mcgill mcmaster u toronto holy',\n",
       "    'honor bill congress passed started making thing cycle random websites sleep',\n",
       "    \"realized none intro statsmetrics classes i taken grad school covered test sets training sets that's kinda crazy\",\n",
       "    'simple linear regression absolute joy sklearn, perhaps even better r terms intuition behind code',\n",
       "    'god bless sklearn python need start teaching stats classes using sklearn library jupyter notebooks asap',\n",
       "    'id argue social science closer data science cs biased',\n",
       "    'canada comes online',\n",
       "    'anti islamist leaders do resolve this; likely produce violence see algerian military',\n",
       "    'rex tillerson lift human rights conditions arms sale bahrain',\n",
       "    \"one best explanations ml it's relationship regressionclassifiers i ever come across\",\n",
       "    'cards humanity matching donations chicago public schools make today',\n",
       "    'advice grad students days go computer science department take class machine learning',\n",
       "    'absolutely fantastic paper ml',\n",
       "    '\"how built fully automated system restocks kitchens coffee amazon\"',\n",
       "    \"worries i'm excited get started day goes price gets higher estimate backlog?\",\n",
       "    \"it's well hours still account verification feedback backlog? i'd really like get on\",\n",
       "    'companies do this descibe intern',\n",
       "    'oh yes, think stem majors college take statistics college students',\n",
       "    'breaking wife french presidential candidate francois fillon facing preliminary charges allegedly fake jobs',\n",
       "    \"pm signs letter formally begin uk's departure european union\",\n",
       "    'overheard reg cafe difference variable value anyway?',\n",
       "    'new nba',\n",
       "    'donald trump signs executive order energy policies rolls back obama era climate change rules says moves include end',\n",
       "    'me ticket say mr albon says dr albon wife person save lives',\n",
       "    'quarter day course cover semesters worth discrete math lin alg combinedin weeks let games begin',\n",
       "    'saying wrong dmv fun live diesnot uchicago',\n",
       "    \"ru stand for? dunno, maybe russia? what's context? says r u'\",\n",
       "    \"bill does pass, call obamacare trumpcare say it's great worked employment numbers\",\n",
       "    'breaking new budget office analysis revised gop health bill reduces deficit less earlier version, improve coverage',\n",
       "    'representing',\n",
       "    \"thanks follow huge fan work would love visit next time i'm dc\",\n",
       "    \"mean repo? means think it's interesting, also you never look again\",\n",
       "    \"hiring interns? interested i'm getting error trying access career center webpage\",\n",
       "    \"initial thoughts yesterday's\",\n",
       "    \"i professionally years, honestly could tell ibm actually does i'm\",\n",
       "    'course skipped minds tell sooner cheers see later today',\n",
       "    'got contacts there? think would little odd stopped by?',\n",
       "    \"i'm pretty sure can free credit signed up\",\n",
       "    'sidebar know capp related orgs dc visit today? gonna swing wanted ideas too',\n",
       "    'advantage everything gets sped use cc made requests single charge',\n",
       "    'credit card give something like free credit months free google cloud platform use',\n",
       "    'using google maps cs project recently remember correctly pretty high limit use a',\n",
       "    '\"mathematicians, pure applied, think something weirdly different statistics right\" james',\n",
       "    'like shootings attacks guns gun deaths year part living us republicannra',\n",
       "    'confirm house commons house lords sit tomorrow normal times',\n",
       "    'remember, people mow unarmed civilians bridge are they murderous criminals',\n",
       "    \"us capp's dc would love catch urban institute you free\",\n",
       "    'students making way dc annual career trek hear various orgs employment opportunities',\n",
       "    '',\n",
       "    'check amazing project',\n",
       "    'cobra govt emergency meeting chaired pm next couple hours',\n",
       "    'confirmed parliament sit normal tomorrow',\n",
       "    '',\n",
       "    'harris building',\n",
       "    'westminster attack know far',\n",
       "    'learned software developers get together stuff envelopes, get lot this',\n",
       "    'visited today disappointed',\n",
       "    'passed microecon',\n",
       "    \"sinn fein's martin mcguinness, northern ireland's former deputy first minister, died aged\",\n",
       "    'excited host upcoming hackathon join us',\n",
       "    'paper absolute game changer incentivising corrupt officials india take smaller bribes genius',\n",
       "    'giggs featuring drakes track',\n",
       "    \"realised drake's new album dropped\",\n",
       "    'long research rewarded cited peers vs used public, many academic fields remain',\n",
       "    \"police man' paris orly airport\",\n",
       "    'original poster returns meant adobe illustrator',\n",
       "    \"links discussion follow breadth ai, mooc's, tutorials etc\",\n",
       "    'oh slack would like learn use ai asap ideas someone could teach me, good course',\n",
       "    'pro tip arent \"code challenged\" havent coding long enough give time, keep pushing,',\n",
       "    'google open sources jpeg encoder reduces file sizes',\n",
       "    'committee women statistics established',\n",
       "    'pet peeve people reply does equal causation tweet study uses randomized',\n",
       "    'we hosting data democracy hackathon join us',\n",
       "    'thank god serena williams',\n",
       "    'breaking netherlands main exit poll suggests anti islam firebrand geert wilders unexpectedly poor showing election',\n",
       "    'going leave here',\n",
       "    \"quarter out last weeks hardest academic career fellow capp's y'all warriors amazing break\",\n",
       "    'excited board run joint cs public policy program',\n",
       "    'happy',\n",
       "    'barely inch snow winter night finals week inches tomorrow, inches tuesday inch wednesday',\n",
       "    'free podcast idea episode recording mock technical interview',\n",
       "    'middle eastern man sure many days worth airport detention clothes pack',\n",
       "    'polsci too',\n",
       "    'fuck happening?',\n",
       "    \"craftsmanship important data science dont desk, instead put macbook pro potter's wheel\",\n",
       "    'post uses fairml build important machine bias work',\n",
       "    \"tomorrow's cs presentation let finishbut group greatest treemap time\",\n",
       "    \"dance moves i'm pulling ridiculous\",\n",
       "    'omfg working demo',\n",
       "    '',\n",
       "    'like women like like coffee unrestricted gendered conceptions intellectual scientific pursuits',\n",
       "    'differentiated e^x hard got polynomial',\n",
       "    'rest wicked',\n",
       "    'statistics conduit dont trust, verify',\n",
       "    'lies, damned lies manipulated data statistics lie, people do',\n",
       "    'yaaaaaaaaaaaaaasssss',\n",
       "    'heh rumman would interested',\n",
       "    \"shoutout google's api making cs122 project possible\",\n",
       "    'knowing code weeks ago marvelling beautysophisticationpower code incredibly rewarding',\n",
       "    'code works',\n",
       "    'ca spell general jefferson beauregard sessions third without l y i n g u n d e r o a t h',\n",
       "    'taught seeing theory visual introduction probability statistics daniel kunin',\n",
       "    \"political commentary codingit's kinda working me\",\n",
       "    'duty keep good fight',\n",
       "    'look back night admonish ever letting happen',\n",
       "    '',\n",
       "    \"fuck lyyyyyiiiiinnnn'\",\n",
       "    'damn thanks reminding ai president world twat',\n",
       "    'strongly support nato, trump says good hear guess policy embrace nato tuesdays thursdays',\n",
       "    'refused intel briefings went advice joint chiefs fuckup',\n",
       "    \"that's fucking problem\",\n",
       "    'pr moment botched military action dare',\n",
       "    'country built backs, blood, sweat tears immigrants',\n",
       "    'military rhetoric extremely dangerous',\n",
       "    'shooting two innocent indians white terrorist??',\n",
       "    'taskforce immigration crime enforcement? sounds like gestapo',\n",
       "    'ca unify law enforcement overlook institutional racism',\n",
       "    'chiraq getting shoutout want great schools high paying jobswith fucking money?',\n",
       "    \"alternative speech story man loves daughteryeah, i'd bang daughter\",\n",
       "    'no rare disease audacity mocked disabled reporter',\n",
       "    'thats aca does',\n",
       "    \"i'm literally screaming incomprehensible sentences substance\",\n",
       "    's3 strikes uchicago',\n",
       "    '',\n",
       "    'somewhere deep inside amazon data center, engineer desperately willing segway go faster',\n",
       "    'hash tables econometricsharris mine yet',\n",
       "    'time bedmodellingdreamsahead',\n",
       "    'got harris blast spotify let data thing',\n",
       "    'clinton campaigns big data simulator went wrong early‚Äîand one noticed',\n",
       "    'google sha 1 collision really gonna fuck internet anything else today cloudflare hold beer',\n",
       "    'manuscripts ‚îîin preparation ‚îîfinal final ‚îîfinal edits ‚îînear final',\n",
       "    'women awarded literature',\n",
       "    'breaking trump administration considers mobilizing many national guard troops round unauthorized immigrants',\n",
       "    'hero',\n",
       "    'minimize sum squared residuals you best fit',\n",
       "    'overfitted models make red poor accuracy makes blue i checked hidden variables you missing few',\n",
       "    \"valentine's day, happy show love equation share ocw someone love\",\n",
       "    'card',\n",
       "    \"data points red data points blue clusters linearly separable it's complicated\",\n",
       "    'you average, mean world me, baby love wo ever deviate',\n",
       "    'get far much satisfaction checking things listi need get',\n",
       "    'damn alessia cara hits close home',\n",
       "    'sup',\n",
       "    '',\n",
       "    '',\n",
       "    'bloody brilliant fave',\n",
       "    'shoutout mfx package r making life easier calculating partial effects probit regressions',\n",
       "    'verdict in devdas soundtrack also conducive productive statistical thinking',\n",
       "    '',\n",
       "    \"one hand, love girlfriend earth other, hate she's imaginary\",\n",
       "    'n r p',\n",
       "    'computer render shimmering fantasy worlds dreams times second me search emails',\n",
       "    'learning high school math could make kids richer later, professor says',\n",
       "    \"academia's crisis relevance role engaged scholar\",\n",
       "    'regression sad',\n",
       "    \"it's anecdote it's data\",\n",
       "    'thesis motivation explained',\n",
       "    'reading blockchain could help reduce global inequality',\n",
       "    'since faked moon landing conspiracy theory white house aligned comfortably',\n",
       "    'publish',\n",
       "    'video like screencast',\n",
       "    'devdas soundtrack surprisingly conducive productive coding would known?',\n",
       "    'google uber api joy use',\n",
       "    'recommends use grad school up',\n",
       "    'discovered r markdown spellcheck feature game changer',\n",
       "    'obama rejects comparison trumps immigration policy own, encourages protests',\n",
       "    \"washington state attorney general announces lawsuit president trump's immigration order\",\n",
       "    'steve mnuchin captain titanic, hed deny ever hitting iceberg',\n",
       "    \"ko ni, leading muslim lawyer adviser myanmar's ruling party, shot dead yangon airport\",\n",
       "    'lt general mark hertling said cnn isis, recruiting pr equivalent abu',\n",
       "    'five reportedly shot dead attack quebec mosque',\n",
       "    'days achieving majority disapproval reagan bush i clinton bush ii obama',\n",
       "    'muslim ban protests erupt nationwide outside white house, trump holds private screening dory',\n",
       "    'shooting quebec city mosque, reports multiple wounded',\n",
       "    'remember cato institute calculated chance killed refugee america billion',\n",
       "    'president united states continues defy order federal court, impeached',\n",
       "    'youll definitely want follow',\n",
       "    'fortune companies founded immigrants children',\n",
       "    \"i'm immigrant served american people dept defense white house served president's bush obama\",\n",
       "    'american deaths us soil foreign terrorists muslim countries immigration ban',\n",
       "    '',\n",
       "    \"that's judicial orders work all\",\n",
       "    'students would love help',\n",
       "    'gotten disturbing reports refusing comply court order',\n",
       "    'round one victory emergency stay issued federal court trump order yale law',\n",
       "    \"signed judge's order refugees going immediately deported\",\n",
       "    'judge ruled today refugees put back planes sent back danger',\n",
       "    'stay granted green card holders nationally brooklyn judge ruled',\n",
       "    'airbnb providing free housing refugees anyone allowed us stayed tuned more, contact urgent',\n",
       "    'news victoryemergency stay reaches',\n",
       "    'judge donnelly stay granted',\n",
       "    'canadian colleagues',\n",
       "    'important information',\n",
       "    'detained ca airport executive order call local hotline sfo lax san',\n",
       "    \"according attorneys, detainees o'hare include month old newborn, us citizens\",\n",
       "    \"o'hare now\",\n",
       "    \"people chicago's o'hare airport standing solidarity people detained trump's\",\n",
       "    \"protestors march o'hare's international terminal chanting hate fear refugees welcome here\",\n",
       "    \"everyone picture attorney o'hare's intl terminal\",\n",
       "    'us tech companies founded generation immigrants apple google facebook amazon oracle ibm uber yahoo emc',\n",
       "    'too',\n",
       "    'aau administration order barring return wvisas fsome countries stranding students please end soon',\n",
       "    \"people affected trump's order\",\n",
       "    'lawyers stationed airports across us know someone entering country, tell sign anything',\n",
       "    'student one countries affected recent executive order please message us',\n",
       "    'translator helped us military iraq detained jfk airport family',\n",
       "    'much money data analysts make? booleans dollars',\n",
       "    'data people show you, suspicious intellectually vigilant be added ineq chapter',\n",
       "    'republicans take control washington, immediately charge taxpayers least billion concrete wall good',\n",
       "    'breaking president trump says intelligence officials told torture works',\n",
       "    'finally, sensible thoughts',\n",
       "    '',\n",
       "    'damn straight',\n",
       "    'indeed turns out, trump swamp',\n",
       "    'trying learn best',\n",
       "    'resistance live streamed twitch',\n",
       "    'literally words need students show up dive in stay it',\n",
       "    'learned capp last week',\n",
       "    'federal climate data backed hope able get all',\n",
       "    'per website may go offline early tomorrow read can',\n",
       "    'one greats',\n",
       "    'respect office president united states damn, moronic bully making challenge',\n",
       "    'long live you never see photograph women signing legislation men',\n",
       "    'advice grader start fighting ignorance knowledge',\n",
       "    \"alternative fact i'm fine\",\n",
       "    \"spicer says there's expansion federal workforce recent years unequivocally false\",\n",
       "    \"me, i'm like smart person, said, like, smart person ever history\",\n",
       "    'hundreds thousands people take part womens marches across america world',\n",
       "    'across world, terrorists dropping weapons giving up president finally said islamic',\n",
       "    'thanks come visit training work public policydatascience',\n",
       "    'hey chris, big fan ideas budding new data scientist like find summer internship?',\n",
       "    'president donald trump signs executive order declaring prompt repeal obamacare official policy',\n",
       "    'breaking white house says trump chief staff priebus issue government wide order immediately freezing regulations',\n",
       "    'feel you, michelle',\n",
       "    'little late perhaps find job entails opening mouth',\n",
       "    'final repatriation flights gambia tomorrow call thomas cook arrange uk flight',\n",
       "    'last week dc republican foreign policy type said trump transition good looks',\n",
       "    'mnuchin makes mistakes complicated paperwork, asks forgiveness customers made mistakes, took',\n",
       "    'office faces parade route wanted remind people coming celebrate mandate',\n",
       "    'results in footnotes go punctuation¬π ¬π course do',\n",
       "    'last energy secretary nuclear physicist one nobel prize rick perry',\n",
       "    'former president george hw bush, hospitalized houston, according chief staff',\n",
       "    'none might want check insinuate something like that',\n",
       "    \"i'm still waiting trump say something global affairs has literally said first kremlin\",\n",
       "    'breaking nigerian state official military jet mistakenly bombs refugee camp, kills',\n",
       "    'standards stopped using copious amount profanity wanted use this',\n",
       "    'breaking president barack obama commutes sentence chelsea manning, leaked army documents serving years',\n",
       "    '',\n",
       "    '¬£ fallen report theresa may signal plans quit single market',\n",
       "    'shoutout',\n",
       "    'britain starts reveal brexit plans one priority restoring british control immigration borders',\n",
       "    \"obama resign day early make biden president ruin trump's merchandise\",\n",
       "    'oh, honey, bless heart',\n",
       "    'president elect potentially compromised hostile foreign govt gonna it? away',\n",
       "    'would please identify cities presently fire?',\n",
       "    'want foreign trip w country matters us, go china closest us, canada you',\n",
       "    'trump makes things slightly better',\n",
       "    \"ap fact check story president obama's mother in law receive lifetime federal pension false\",\n",
       "    'yes, president elect, mlk weekend, says freedom rider, sncc coordinator civil rights icon john lewis',\n",
       "    \"civil rights hero i'm pee play civil rights hero i'm pee play\",\n",
       "    'discovered river dolphins whhaaaatttt bless planet earth ii',\n",
       "    \"i'm mins planet earth ii i'm already blown away\",\n",
       "    'holy shitrevoke phd',\n",
       "    'seen c span2 senate passes resolution, moves toward repeal affordable care act',\n",
       "    'press conference, trump filled room paid staffers clapped cheered blasted media',\n",
       "    'hear russians footage obama playing basketball fixing economy',\n",
       "    \"it's tough competition, think there's bigger liar trumpworld kellyanne conway incredible\",\n",
       "    'press conference impossible watch',\n",
       "    'obama without doubt, one greatest orators time period',\n",
       "    'go knock park obama',\n",
       "    'street almost completely shutdown secret service, police barricades everywhere obama valois',\n",
       "    'fucking kidding me???',\n",
       "    'trump, understand paying fucken wall clear us tax payers pay',\n",
       "    '',\n",
       "    \"i'm board flight abu dhabi bet, land, trump tweetback plan congress fund\",\n",
       "    'trump team broke w precedent issued blanket edict denying obama political ambassadors extensions post 120',\n",
       "    'time move on say someone crush, issue national security',\n",
       "    'doctoral student advisor walk bar advisor orders rough draft sit awkward silence',\n",
       "    'filled simple graphics synthesize otherwise complex topic concise clear highly recommended',\n",
       "    'one concise well written explanations come across excellent work i sharing around network',\n",
       "    '',\n",
       "    '',\n",
       "    '',\n",
       "    '',\n",
       "    'apologize in flight announcement require assistance doctorate holder assist row',\n",
       "    'gender bias academe annotated bibliography',\n",
       "    'friendly holiday function reminder',\n",
       "    'ca say anything nice¬π ¬πsay footnote',\n",
       "    'end history aleppo version quite fukuyama intended',\n",
       "    \"leave voters willing see economy suffer, unemployment money hospitals down, reduce eu immigration that's\",\n",
       "    '',\n",
       "    'fantastic read',\n",
       "    \"rex tillerson's wikipedia page edited overnight removed? award russian order friendship\",\n",
       "    'breaking state department source tells trump considering disgraced ex fox news boss roger ailes secretary',\n",
       "    'nobel lecture, juan manuel santos cited advice hks faculty motivation trying times',\n",
       "    'cappharris grades got feeling like',\n",
       "    \"you looking tillerson's thoughts stuff might matter secretary state, try first\",\n",
       "    'update turkey least killed, hurt twin blasts outside istanbul soccer stadium',\n",
       "    'i put good money gop try convert anger russian interference election',\n",
       "    'given supposedly us political institution hacked russia, rnc share',\n",
       "    'dutch court finds populist anti islam lawmaker geert wilders guilty hate speech party leads polls advance',\n",
       "    'south korea parliament votes impeach president park geun hye corruption scandal',\n",
       "    'south korea parliament votes impeach park geun hye votes',\n",
       "    'work life balance delicate sunday night art feeling like wasted entire weekend',\n",
       "    'winston churchill born read writing advice sent officials prime',\n",
       "    'breaking senior official trump offered retired lt gen michael flynn job national security adviser',\n",
       "    \"it's plagiarism it's ironic re reading commentary linguistic ownership\",\n",
       "    'evidence life life burning well, poetry ash',\n",
       "    'daily existence',\n",
       "    \"it's comment question\",\n",
       "    'transport london utilizing data optimize service provision',\n",
       "    \"brexit means brexit andthat's far\",\n",
       "    'correlation education white support trump disappears control racial resentment',\n",
       "    'thank talk open floor passive aggressive requests show slide,',\n",
       "    'breaking israeli ministerial committee approves bill legalize illegal outposts west bank built private',\n",
       "    'bannonbreitbart setting wh comms strategy, long look back fondly time fox news',\n",
       "    'education much stronger predictor county level change income',\n",
       "    'trump support partly economic insecurity, even moreso race gender',\n",
       "    'breaking magnitude quake strikes south island new zealand usgs',\n",
       "    \"j hey here's idea b joe j let's say get faculty job b j could team teach a  b j could share\",\n",
       "    'quick question trump first president elect family members transition team?',\n",
       "    'bewilderingly, expresses bewilderment minorities; muslims; immigrants fear',\n",
       "    \"news release trump's transition team said reince priebus steve bannon would work partners\",\n",
       "    \"steve bannon breitbart news named president elect donald trump's chief strategist senior counselor\",\n",
       "    'stephen bannon senior counselor got shitting me?',\n",
       "    'trump anti establishment appoints reince priebus chief staff ca get establishment that',\n",
       "    \"david chappelle's snl monologue full\",\n",
       "    '\"we waste two years tours world doesnt know\" eu commission president',\n",
       "    'feeling advisor takes research presentation',\n",
       "    'south koreans gather en masse protest president',\n",
       "    'last year leonard cohen recorded flanders fields written canadian soldier john mccrae tribute',\n",
       "    'wins florida, forcing firewall michigan, wisconsin pennsylvania',\n",
       "    'indiana projected abc news full results',\n",
       "    'vermont projected abc news full results',\n",
       "    'kentucky projected abc news full results',\n",
       "    'm56 strikes km ne min ago effects reported witnesses',\n",
       "    \"it's beautiful day neighbourhood\",\n",
       "    'response retraction letter',\n",
       "    'staff armed tranquiliser guns currently scouring london zoo escaped gorilla',\n",
       "    \"mean, would never guessed she'd say that respect children brilliant\",\n",
       "    'trump, understand you coming many judges supreme court?',\n",
       "    'clinton calls universal background checks firearms purchases yes years, americans die',\n",
       "    'picking judges is selective dimwit',\n",
       "    'bear mind clinton law degree yale trump does understand definition sexual assault conception law',\n",
       "    'tremendous hatred, says world renowned expert hatred hate speech',\n",
       "    'saying irredeemable bad saying sexually assault women?',\n",
       "    'shoutout',\n",
       "    'foreign policy spokesperson hillary deleted',\n",
       "    'said osmosis? big word',\n",
       "    'calls deploarablw call them african americans rapist mexicans grab py extreme vetting',\n",
       "    'i bet good money donald does know mosul',\n",
       "    \"agree american ground troops syria let's learn mistakes iraq\",\n",
       "    'syria russia',\n",
       "    'oop pence trump are speaking',\n",
       "    'trump look, do even know running mate is, do agree all',\n",
       "    'trump would cut taxes rich poor, raising taxes middle clinton would raise taxes rich',\n",
       "    'ice did endorse you isis endorsed you',\n",
       "    'foreign policy requires something trump knows nothing about nuance in progress word salad proof',\n",
       "    'moderators able mute mics,',\n",
       "    \"fact check yes, trump's iraq war claim debunked\",\n",
       "    'man running president united states says knows nothing russia',\n",
       "    'wait paid taxes last ten years? you?',\n",
       "    'trump promised make wealthy pay fair share making pay less',\n",
       "    \"reminder donald trump's tax plan would absolutely worthless middle class\",\n",
       "    'cutting bigly? uneducated',\n",
       "    \"last fact checked trump's repeated claim iraq war\",\n",
       "    'clinton says trump did apologize insulting comments thats true',\n",
       "    'islamophobia question, trump says muslims collectively responsible terrorism',\n",
       "    'someone point direction office us government? also dont wait audit release taxes',\n",
       "    'dear gop congrats nominated misogynist, racist, vulgar, lying, ignorant, mad man nominee oh,',\n",
       "    \"trump wants muslim immigrants sign values' groping women? relentless lying? tax evasion? muslim\",\n",
       "    'trump lies refugees years long vetting process refugees go resettled',\n",
       "    \"record, ban', originally announced, condemned trump's vp candidate, still\",\n",
       "    'trump says syrian refugees coming thousands huh? far canada admitted',\n",
       "    'answer question job pay attention former debate moderators, past future',\n",
       "    'says captain khan would alive today president, does apologize family,',\n",
       "    'republicans love term islamic terrorism do ask define',\n",
       "    \"you right islamophobia, that's shame but blah radical islamic terrorism blah blah\",\n",
       "    'islamaphobia shame? solution label muslims, track muslims, make wear badges??',\n",
       "    'trump says us giving billion iran thats false',\n",
       "    'plans good solves it',\n",
       "    'anderson playing games today',\n",
       "    \"structure donald's responses?? needs fire debate prep interns\",\n",
       "    'sniffling',\n",
       "    'im gentleman??',\n",
       "    'boooooooom clinton rap battle game strong',\n",
       "    \"donald's trump sniffing lot today\",\n",
       "    'again, prepared, did, shows',\n",
       "    'gotta shut studio audience up presidential debate jerry springer show content',\n",
       "    'trump says charge, hillary clinton would jail donald, america, defeat election opponents,',\n",
       "    'hillary clinton deserves nobel peace prize grabbing trump pussy right',\n",
       "    'bill clinton abusive abusiveperfect logic trump',\n",
       "    'minutes hillary wiped floor trump',\n",
       "    'trump fact chk us trade deficit trade deficit goods; surplus',\n",
       "    'trump created jobs politifact claiming women respect him',\n",
       "    \"bragging sexual assault acceptable?' grope women?' going beat isis'\",\n",
       "    'anderson cooper games tonight',\n",
       "    \"go clinton's response trump's comments\",\n",
       "    'record live medieval times, fact, live safest time history',\n",
       "    'room talk????????',\n",
       "    'bring law order back',\n",
       "    'handshake',\n",
       "    'please shimmy',\n",
       "    '\"well start shortly\"',\n",
       "    'get ready play bingo us',\n",
       "    'gonna spicy debate',\n",
       "    'future harris arrived',\n",
       "    'shimon peres, former israeli prime minister nobel peace prize winner, dead age rip',\n",
       "    'breaking israeli media former israeli president shimon peres died two weeks suffering major stroke',\n",
       "    'former israeli pm president shimon peres dies aged following stroke two weeks ago, reports say',\n",
       "    'moment fully comprehend much work end year',\n",
       "    'so, recap, cambridge, stanford ubc recently selected mcgill grads leaders',\n",
       "    'first baby born using new person fertility technique carried us scientists, new scientist reveals',\n",
       "    'greatest debate time hillary fun, slayed',\n",
       "    'clinton calls trump perv racist',\n",
       "    'trump keeps dropping names, acronyms, allusions low information undecided voters idea about, without',\n",
       "    'please, please ask trump policy first use is, hillary',\n",
       "    '',\n",
       "    'trump became b 52 aviation expert',\n",
       "    'clinton might first person human history fun presidential debate',\n",
       "    'man gets provoked tweet hand nuclear codes',\n",
       "    \"breaking blowing another country's ship act war according orangutang\",\n",
       "    'someone needs call sean hannity right fucking second',\n",
       "    \"trump's witness iraq sean hannity?? might well call youngest child witness sheesh\",\n",
       "    'trump war iraq holt record says otherwise',\n",
       "    'please like tweet fan',\n",
       "    'this',\n",
       "    'thanks',\n",
       "    'record preventing lone wolf attacks close impossible incredibly stupid question',\n",
       "    'cyber one things',\n",
       "    'resolved use phrase cyber qualified president century',\n",
       "    'breaking hacker collectives recruiting morbidly obese cyber security experts',\n",
       "    'terrible disrespect?? mean, respect?? politicians talk good',\n",
       "    \"even trump's claims hillary staff obama true didnt spend five years publicly questioning obama's\",\n",
       "    'wtf birther rumours got moving onto isis?? answer question',\n",
       "    'politicians talk good bragadocious',\n",
       "    'stop frisk unconstitutional statistically ineffective orangutan',\n",
       "    'former dean stephen toope named vice chancellor cambridge',\n",
       "    \"clinton's response implicit bias strong\",\n",
       "    'clinton calls background checks buy guns polls show even nra members overwhelmingly support universal',\n",
       "    'white man telling black man stop and frisk did involve profiling front million ppl',\n",
       "    'live fact check clinton right guns biggest cause death young black men',\n",
       "    'trump endorsed stop frisk statistically proven ineffective racially biased also unconstitutional',\n",
       "    'trump wants new season law order',\n",
       "    \"hillary, fuck's sake, said country's fucked iraq war republican endeavor bush's war,\",\n",
       "    'talk race hold seats',\n",
       "    'omg brought architect in reeeekkkkkkkttttt',\n",
       "    'trump us companies do pay taxes bad do pay taxes smart',\n",
       "    'say bragadocious? didnt know word? life lie',\n",
       "    'wonder donald trump hiding tax returns',\n",
       "    'trump literally contradicted fed interest rates',\n",
       "    'hilary fighting isis? fuck happened?',\n",
       "    'trump going cut taxes big league, going raise taxes big league',\n",
       "    'hey guys big league end story',\n",
       "    'fact check take pick',\n",
       "    'hillary tell name is bill do defend bils mistakes nafta',\n",
       "    \"plan trump do wrote book it it's called stronger together pick tomorrow\",\n",
       "    \"trump denied said climate change hoax created chinese say here's tweet\",\n",
       "    'breaking trump believes forms energy',\n",
       "    'rooting housing market collapse? called business, interjects yikes',\n",
       "    'million people lost homes thats called business',\n",
       "    'wait mexican cookies gonna trend twitter',\n",
       "    \"want happy it's important me heat\",\n",
       "    'ms secretary ok? condescending prick',\n",
       "    ...],\n",
       "   'favorite_count': [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    9,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    4,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    13,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    11,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    5,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    22,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    49,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    8,\n",
       "    0,\n",
       "    5,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    26,\n",
       "    3,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    9,\n",
       "    0,\n",
       "    2,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    6,\n",
       "    2,\n",
       "    40,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    9,\n",
       "    1,\n",
       "    2,\n",
       "    0,\n",
       "    1,\n",
       "    6,\n",
       "    8,\n",
       "    2,\n",
       "    10,\n",
       "    2,\n",
       "    0,\n",
       "    3,\n",
       "    5,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    4,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    7,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    7,\n",
       "    2,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    6,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    5,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    ...],\n",
       "   'hashtags': ['opendata',\n",
       "    'NLP',\n",
       "    'spaCy',\n",
       "    'Metis',\n",
       "    'TopicModelling',\n",
       "    'PCA',\n",
       "    'SVD',\n",
       "    'SentimentAnalysis',\n",
       "    'SoDS17',\n",
       "    'Metis',\n",
       "    'SoDS17',\n",
       "    'MachineLearning',\n",
       "    'Python',\n",
       "    'SoDS17',\n",
       "    'Python',\n",
       "    'AWS',\n",
       "    'S3',\n",
       "    'SoDS17',\n",
       "    'adoption',\n",
       "    'ETH',\n",
       "    'SoDS17',\n",
       "    'EC2',\n",
       "    'SoDS17',\n",
       "    'AWS',\n",
       "    'AWS',\n",
       "    'boto3',\n",
       "    'SoDS17',\n",
       "    'machinelearningflashcards',\n",
       "    'SquadGoals',\n",
       "    'Hodl',\n",
       "    'Ethereum',\n",
       "    'liftoff',\n",
       "    'MoochMadness',\n",
       "    'MoochMadness',\n",
       "    'Chicago',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'sklearn',\n",
       "    'SoDS17',\n",
       "    'EEA',\n",
       "    'Ethereum',\n",
       "    'Adoption',\n",
       "    'datascience',\n",
       "    'SoDS17',\n",
       "    'DataJanitor',\n",
       "    'algorithms',\n",
       "    'AI',\n",
       "    'MachineLearning',\n",
       "    'Metis',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'Python',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'Python',\n",
       "    'Metis',\n",
       "    'cantstopwontstop',\n",
       "    'Python',\n",
       "    'SoDS17',\n",
       "    'Python',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'SoDS17',\n",
       "    'CAPP',\n",
       "    'SoDS17',\n",
       "    'CAPP',\n",
       "    'July4',\n",
       "    'SoDS17',\n",
       "    'ETH',\n",
       "    'Mathematics',\n",
       "    'McGillPride',\n",
       "    'McGillPride',\n",
       "    'CAPP30271',\n",
       "    'adoption',\n",
       "    'SoDS17',\n",
       "    'CAPP',\n",
       "    'SoDS17',\n",
       "    'MIT',\n",
       "    'OCW',\n",
       "    'SoDS17',\n",
       "    'partofLSE',\n",
       "    'ThinkStats',\n",
       "    'SoDS17',\n",
       "    'AI',\n",
       "    'BKC',\n",
       "    'SoDS17',\n",
       "    'ThinkStats',\n",
       "    'CAPP',\n",
       "    'SodS17',\n",
       "    'SoDS',\n",
       "    'CAPP',\n",
       "    'ETH',\n",
       "    'ETH',\n",
       "    'GE2017',\n",
       "    'GeneralElection',\n",
       "    'iVoted',\n",
       "    'WWDC',\n",
       "    'LondonAttack',\n",
       "    'MasterofNone',\n",
       "    'CAPP',\n",
       "    'CAPP',\n",
       "    'CAPPemotions',\n",
       "    'polsky',\n",
       "    'UChicago',\n",
       "    'ETH',\n",
       "    'Ethereum',\n",
       "    'adoption',\n",
       "    'ETH',\n",
       "    'GE2017',\n",
       "    'GeneralElection',\n",
       "    'UChicago',\n",
       "    'ETH',\n",
       "    'Ethereum',\n",
       "    'ETH',\n",
       "    'Ethereum',\n",
       "    'adoption',\n",
       "    'ETH',\n",
       "    'Ethereum',\n",
       "    'ETH',\n",
       "    'Ethereum',\n",
       "    'pycon2017',\n",
       "    'ETH',\n",
       "    'ETHEREUM',\n",
       "    'ETH',\n",
       "    'ETHEREUM',\n",
       "    'tothemoon',\n",
       "    'hodl',\n",
       "    'ETH',\n",
       "    'ETHEREUM',\n",
       "    'ETHEREUM',\n",
       "    'PREACH',\n",
       "    'CAPP',\n",
       "    'CAPP30254',\n",
       "    'CAPP',\n",
       "    'Ivecomesofar',\n",
       "    'DataScience',\n",
       "    'MuslimBan',\n",
       "    'Gabr',\n",
       "    'CAPP',\n",
       "    'OnThisDay',\n",
       "    'odsc',\n",
       "    'curecancer',\n",
       "    'AI',\n",
       "    'pydataldn',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'UNHCR',\n",
       "    'jesuswasarefugee',\n",
       "    'UNHCR',\n",
       "    'lgbtrefugees',\n",
       "    'ODSCEast',\n",
       "    'prismoji',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ibm',\n",
       "    'odsc',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'Julia',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'odsc',\n",
       "    'ODSCEast',\n",
       "    'ODSC',\n",
       "    'datascience',\n",
       "    'ODSCEast',\n",
       "    'odsc',\n",
       "    'odsceast',\n",
       "    'bigdata',\n",
       "    'policy',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'MachineLearning',\n",
       "    'CAPP',\n",
       "    'odsc',\n",
       "    'odsc',\n",
       "    'cxo',\n",
       "    'odsc',\n",
       "    'datascience',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'ODSC',\n",
       "    'datascience',\n",
       "    'analytics',\n",
       "    'bigdata',\n",
       "    'MachineLearning',\n",
       "    'DL',\n",
       "    'ODSC',\n",
       "    'odsc',\n",
       "    'Boston',\n",
       "    'Boston',\n",
       "    'Gold',\n",
       "    'ODSC',\n",
       "    'CAPP',\n",
       "    'Harris',\n",
       "    'ETH',\n",
       "    'marchforscience',\n",
       "    'CMLVCSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'CMLVCSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'FOMO',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'MachineLearningSummit',\n",
       "    'UChicago',\n",
       "    'CAPP',\n",
       "    'CAPP',\n",
       "    'F8',\n",
       "    'science',\n",
       "    'MachineLearning',\n",
       "    'MachineLearning',\n",
       "    'CAPP',\n",
       "    'Matplotlib',\n",
       "    'DataViz',\n",
       "    'Pandas',\n",
       "    'MachineLearning',\n",
       "    'CAPP',\n",
       "    'ifinallyseethelight',\n",
       "    'CAPP',\n",
       "    'ML',\n",
       "    'datamodels',\n",
       "    'MachineLearning',\n",
       "    'UChicago',\n",
       "    'Python',\n",
       "    'CAPP',\n",
       "    'DataScience',\n",
       "    'BigData',\n",
       "    'DataScientists',\n",
       "    'Harris',\n",
       "    'CAPP',\n",
       "    'United',\n",
       "    'CAPP30271',\n",
       "    'mathematicalrevelations',\n",
       "    'Drake',\n",
       "    'bigmistake',\n",
       "    'Trump',\n",
       "    'CAPP',\n",
       "    'MLPubPol',\n",
       "    'Harris',\n",
       "    'greys',\n",
       "    'spottedUChicago',\n",
       "    'Databases',\n",
       "    'Harris',\n",
       "    'Harris',\n",
       "    'MachineLearning',\n",
       "    'DanceParty',\n",
       "    'Harris',\n",
       "    'Harris',\n",
       "    'datadriven',\n",
       "    'sklearn',\n",
       "    'Python',\n",
       "    'BestSchoolDay',\n",
       "    'Brexit',\n",
       "    'Harris',\n",
       "    'londonattack',\n",
       "    'Squad',\n",
       "    'HarrisCareerTrek',\n",
       "    'NLP',\n",
       "    'machilearning',\n",
       "    'IDPs',\n",
       "    'HarrisCareerTrek',\n",
       "    'HarrisCareerTrek',\n",
       "    'ByeKonstantin',\n",
       "    'NoMoreEconForLife',\n",
       "    'Chicago',\n",
       "    'Peckham',\n",
       "    'TBT',\n",
       "    'Chicago',\n",
       "    'PiDay',\n",
       "    'CAPP',\n",
       "    'Harris',\n",
       "    'WEHAVEADEMO',\n",
       "    'WHATISLOVE',\n",
       "    'BABYDONTHURTME',\n",
       "    'NOMORE',\n",
       "    'CS122',\n",
       "    'CAPP',\n",
       "    'DOYOUTHINKPEOPLEPITYUS',\n",
       "    'IMGOINGTOCRY',\n",
       "    'IDLIKETOTHANKTHEACADEMY',\n",
       "    'FORMYCOMPSCIPTSD',\n",
       "    'CS122',\n",
       "    'CAPP',\n",
       "    'Statistics',\n",
       "    'BigData',\n",
       "    'DataScience',\n",
       "    'CAPPemotions',\n",
       "    'stats',\n",
       "    'Iwantmyownpodcast',\n",
       "    'JointSession',\n",
       "    'Jointsession',\n",
       "    'Jointsession',\n",
       "    'JointSession',\n",
       "    'JointSession',\n",
       "    'JointSession',\n",
       "    'JointSession',\n",
       "    'Jointsession',\n",
       "    'SouthSide',\n",
       "    'JointAddress',\n",
       "    'JointAddress',\n",
       "    'CAPP',\n",
       "    'modellingdreamsahead',\n",
       "    'Modelling',\n",
       "    'all',\n",
       "    'night',\n",
       "    'long',\n",
       "    'NobelPrize',\n",
       "    'DataScienceValentines',\n",
       "    'science',\n",
       "    'valentinesday',\n",
       "    'DataScienceValentines',\n",
       "    'learntolivealittle',\n",
       "    'academicvalentine',\n",
       "    'academicvalentine',\n",
       "    'AcademicValentine',\n",
       "    'Harris',\n",
       "    'AcademicValentine',\n",
       "    'MuslimBan',\n",
       "    'BREAKING',\n",
       "    'MuslimBan',\n",
       "    'SFO',\n",
       "    'MuslimBanprotest',\n",
       "    'ACLU',\n",
       "    'MuslimBan',\n",
       "    'WelcometoScotland',\n",
       "    'Preach',\n",
       "    'Resistance',\n",
       "    'draintheswamp',\n",
       "    'DataSci',\n",
       "    'Datagetsitdone',\n",
       "    'Harris',\n",
       "    'DataRefuge',\n",
       "    'opengov',\n",
       "    'climatechange',\n",
       "    'opendata',\n",
       "    'justsaying',\n",
       "    'womensmarch',\n",
       "    'inauguration',\n",
       "    'McGillPride',\n",
       "    'DanielLevitin',\n",
       "    'budget',\n",
       "    'ACA',\n",
       "    'ObamaFarewell',\n",
       "    'ObamaLegacy',\n",
       "    'Russia',\n",
       "    'impostersyndrome',\n",
       "    'harris',\n",
       "    'gradschoolproblems',\n",
       "    'onthisday',\n",
       "    'RIPLeonardCohen',\n",
       "    'DonaldTrump',\n",
       "    'HillaryClinton',\n",
       "    'ElectionNight',\n",
       "    'election2016',\n",
       "    'election2016',\n",
       "    'election2016',\n",
       "    'earthquake',\n",
       "    'terremoto',\n",
       "    'Roma',\n",
       "    'Italy',\n",
       "    'fall',\n",
       "    'mcgill',\n",
       "    'montreal',\n",
       "    'Debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'Chicago',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'Debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'Debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'CNNRealityCheck',\n",
       "    'DonaldTrump',\n",
       "    'debate',\n",
       "    'CNNRealityCheck',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'GRABHERBYTHEP',\n",
       "    'DontDebateonCoke',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'slay',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'SVU',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'debate',\n",
       "    'FutureHarris',\n",
       "    'DataGetsItDone',\n",
       "    'TheCyber',\n",
       "    'facts',\n",
       "    'BESTTVSHOW',\n",
       "    'debatenight',\n",
       "    'Debates2016',\n",
       "    'debatenight',\n",
       "    'debatenight',\n",
       "    'KINETIC',\n",
       "    'POTENTIAL',\n",
       "    'Debates2016',\n",
       "    'debatenight',\n",
       "    'DebateNight',\n",
       "    'sosweet',\n",
       "    'debatenight',\n",
       "    'debatenight',\n",
       "    'debatenight',\n",
       "    'ImWithHer',\n",
       "    'FutureHarris',\n",
       "    'RussellSquare',\n",
       "    'RussellSquare',\n",
       "    'Erdogan',\n",
       "    'AtaturkAirport',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Harbiye',\n",
       "    'BreakingNews',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Turkey',\n",
       "    'turkey',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Turkey',\n",
       "    'Photo',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Turkey',\n",
       "    'MilitaryCoup',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Istanbul',\n",
       "    'Turkey',\n",
       "    'coup',\n",
       "    'Erdogan',\n",
       "    'Turkey',\n",
       "    'Syria',\n",
       "    'ISIL',\n",
       "    'Russia',\n",
       "    'Egypt',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Turkey',\n",
       "    'Turkey',\n",
       "    'Updated',\n",
       "    'Breaking',\n",
       "    'Turkey',\n",
       "    'Baghdad',\n",
       "    'Istanbul',\n",
       "    'Atat√ºrk',\n",
       "    'Brexit',\n",
       "    'EUref',\n",
       "    'indyref2',\n",
       "    'Brexit',\n",
       "    'EUref',\n",
       "    'Leave',\n",
       "    'Brexit',\n",
       "    'EUref',\n",
       "    'Brexit',\n",
       "    'EURefResults',\n",
       "    'Brexit',\n",
       "    'EUref',\n",
       "    'EUref',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'Leave',\n",
       "    'EUref',\n",
       "    'EURef',\n",
       "    'Leave',\n",
       "    'EUref',\n",
       "    'EUref',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EUref',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EURef',\n",
       "    'EUref',\n",
       "    'EUref',\n",
       "    'EURef',\n",
       "    'ivoted',\n",
       "    'StrongerIn',\n",
       "    'EUref',\n",
       "    'phdchat',\n",
       "    'PhD',\n",
       "    'research',\n",
       "    'HappyFathersDay',\n",
       "    'EUref',\n",
       "    'DDay',\n",
       "    'BreakingNews',\n",
       "    'EgyptAir',\n",
       "    'FlightMS804',\n",
       "    'EgyptAir',\n",
       "    'EgyptAir',\n",
       "    'EgyptAir',\n",
       "    'London',\n",
       "    'LondonElects',\n",
       "    'PanamaPapers',\n",
       "    'science',\n",
       "    'science',\n",
       "    'AcademicValentines',\n",
       "    'Conversation',\n",
       "    'rstats',\n",
       "    'GOPDebate',\n",
       "    'RandPaul',\n",
       "    'ChrisChritie',\n",
       "    'Christie',\n",
       "    'realitycheck',\n",
       "    'rstats',\n",
       "    'rstats',\n",
       "    'BreakingNews',\n",
       "    'Turkey',\n",
       "    'Ankara',\n",
       "    'Turkey',\n",
       "    'Mars',\n",
       "    'Saudi',\n",
       "    'Egypt',\n",
       "    'militants',\n",
       "    'Army',\n",
       "    'distractinglysexy',\n",
       "    'BREAKING',\n",
       "    'Houthi',\n",
       "    'QueensSpeech',\n",
       "    'StateOpening',\n",
       "    'ISIS',\n",
       "    'rstats',\n",
       "    'statistics',\n",
       "    'analytics',\n",
       "    'bigdata',\n",
       "    'MohamedFahmy',\n",
       "    'AlJazeera',\n",
       "    'Egypt',\n",
       "    'GE2015',\n",
       "    'live',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'Conservative',\n",
       "    'Labour',\n",
       "    'SNP',\n",
       "    'LibDems',\n",
       "    'Plaid15',\n",
       "    'UKIP',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'Labour',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'GE2015',\n",
       "    'Conservative',\n",
       "    'Labour',\n",
       "    'SNP',\n",
       "    'LibDems',\n",
       "    'Plaid15',\n",
       "    'UKIP',\n",
       "    'Greens',\n",
       "    'BigData',\n",
       "    'BigData',\n",
       "    'LeonardNimoy',\n",
       "    'LegionOfGeek',\n",
       "    'CORe',\n",
       "    'AmericanSniper',\n",
       "    'NUDivest',\n",
       "    'BreakingNews',\n",
       "    'Yemenis',\n",
       "    'LSEdata',\n",
       "    'Hezbollah',\n",
       "    'Iraq',\n",
       "    'ISIS',\n",
       "    'Derna',\n",
       "    'Ukraine',\n",
       "    'ceasefire',\n",
       "    'MinskSummit',\n",
       "    'ChapelHillShooting',\n",
       "    'DataScience',\n",
       "    'FGM',\n",
       "    'EndFGM',\n",
       "    'TogethertoEndFGM',\n",
       "    'RegisterToVote',\n",
       "    'TransAsia',\n",
       "    'Taiwan',\n",
       "    'Jordan',\n",
       "    'ISIS',\n",
       "    'kickass',\n",
       "    'TransAsia',\n",
       "    'TransAsia',\n",
       "    'DataScientists',\n",
       "    'DataScience',\n",
       "    'Toronto',\n",
       "    'Rotman',\n",
       "    'Charlie_Hebdo',\n",
       "    'Egypt',\n",
       "    'religion',\n",
       "    'CharlieHebdo',\n",
       "    'CharlieHebdo',\n",
       "    'CharlieHebdo',\n",
       "    'JeSuisCharlie',\n",
       "    'streetart',\n",
       "    'CharlieHebdo',\n",
       "    'parisattack',\n",
       "    'Montreal',\n",
       "    'JeSuisCharlie',\n",
       "    'polmtl',\n",
       "    'cdnpoli',\n",
       "    'Syria',\n",
       "    'SydneySiege',\n",
       "    'sydneysiege',\n",
       "    'sydneysiege',\n",
       "    'sydneysiege',\n",
       "    'SydneySiege',\n",
       "    'SydneySiege',\n",
       "    'SydneySiege',\n",
       "    'sydneysiege',\n",
       "    'sydneysiege',\n",
       "    'sydneysiege',\n",
       "    'sydneysiege',\n",
       "    'MartinPlaceSiege',\n",
       "    'Sydney',\n",
       "    'Mubarak',\n",
       "    'FergusonDecision',\n",
       "    'Ferguson',\n",
       "    'MichaelBrown',\n",
       "    'BREAKING',\n",
       "    'Sisi',\n",
       "    'Egypt',\n",
       "    'CharingCross',\n",
       "    'Eurozone',\n",
       "    'ttrends14',\n",
       "    'France',\n",
       "    'Saudi',\n",
       "    'Lebanese',\n",
       "    'Lebanon',\n",
       "    'Syria',\n",
       "    'Lebanon',\n",
       "    'London',\n",
       "    'indyref',\n",
       "    'Indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'Scotland',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'Scotland',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'indyref',\n",
       "    'Montreal',\n",
       "    'Alouettes',\n",
       "    'Tunisia',\n",
       "    'ISIS',\n",
       "    'socialmedia',\n",
       "    'Iraq',\n",
       "    'aid',\n",
       "    'Syria',\n",
       "    'R2P',\n",
       "    'Ferguson',\n",
       "    'BlackHat',\n",
       "    'DigitalLiteracy',\n",
       "    'Iraq',\n",
       "    'Mosul',\n",
       "    'Erbil',\n",
       "    'SouthSudan',\n",
       "    'Ukraine',\n",
       "    'Monstermind',\n",
       "    'syria',\n",
       "    'msf',\n",
       "    'Master',\n",
       "    'Postgraduate',\n",
       "    'Diplomacy',\n",
       "    'IS',\n",
       "    'Iraq',\n",
       "    'US',\n",
       "    'ISIS',\n",
       "    'Iraq',\n",
       "    'IS',\n",
       "    'ISIS',\n",
       "    'Israel',\n",
       "    'Hamas',\n",
       "    'Gaza',\n",
       "    'Kerry',\n",
       "    'BREAKING',\n",
       "    'Israeli',\n",
       "    'Gaza',\n",
       "    'BreakingNews',\n",
       "    'MH17',\n",
       "    'Nato',\n",
       "    'Gaza',\n",
       "    'Palestine',\n",
       "    'NetNeutrality',\n",
       "    'NetFreedom',\n",
       "    'MandelaDay',\n",
       "    'time2serve',\n",
       "    'Gaza',\n",
       "    'twitterversary',\n",
       "    'bornontheNHS',\n",
       "    'sorrynotsorry',\n",
       "    'geek',\n",
       "    'nerd',\n",
       "    'DDay70',\n",
       "    'Nigeria',\n",
       "    'BokoHaram',\n",
       "    'BokoHaram',\n",
       "    'breaking',\n",
       "    'Iraq',\n",
       "    'Syria',\n",
       "    'BokoHaram',\n",
       "    'r2p',\n",
       "    'Afghanistan',\n",
       "    'Privacy',\n",
       "    'Israel',\n",
       "    'Palestine',\n",
       "    'Russia',\n",
       "    'Syria',\n",
       "    'R2P',\n",
       "    'polisci',\n",
       "    'bigdata',\n",
       "    'DACnews',\n",
       "    'BreakingNews',\n",
       "    'ICC',\n",
       "    'Qaddafi',\n",
       "    'Libya',\n",
       "    'France',\n",
       "    'Mali',\n",
       "    'R2P',\n",
       "    'wefhyperc',\n",
       "    'wef',\n",
       "    'peacekeeping',\n",
       "    'Myanmar',\n",
       "    'Yale2014',\n",
       "    'CARcrisis',\n",
       "    'simlandia',\n",
       "    'Solidarit√©',\n",
       "    'simlandia',\n",
       "    'ICC',\n",
       "    'Syria',\n",
       "    'simlandia',\n",
       "    'BREAKING',\n",
       "    'BringBackOurGirls',\n",
       "    'MSF',\n",
       "    'Syria',\n",
       "    'HumTech2014',\n",
       "    'Syria',\n",
       "    'war',\n",
       "    'Egypt',\n",
       "    'Sisi',\n",
       "    'BREAKING',\n",
       "    'Yemen',\n",
       "    'refugees',\n",
       "    'IDPs',\n",
       "    'returnees',\n",
       "    'bringbackourgirls',\n",
       "    'Saudi',\n",
       "    'Iran',\n",
       "    'Afghanistan',\n",
       "    'CSISLive',\n",
       "    'CARcrisis',\n",
       "    'Ukraine',\n",
       "    'Syria',\n",
       "    'humanitarian',\n",
       "    'Kramatorsk',\n",
       "    'Syria',\n",
       "    'Aleppo',\n",
       "    'r2p',\n",
       "    'MERS',\n",
       "    'Saudi',\n",
       "    'R2P',\n",
       "    'Myanmar',\n",
       "    'genocide',\n",
       "    'cdnpoli',\n",
       "    'Norway',\n",
       "    'ArabSpring',\n",
       "    'WinstonChurchill',\n",
       "    'Harvard',\n",
       "    'BreakingNews',\n",
       "    'Yemen',\n",
       "    'Nigeria',\n",
       "    'Myanmar',\n",
       "    'genocide',\n",
       "    'JohnnieCarson',\n",
       "    'Dallaire',\n",
       "    'RIP'],\n",
       "   'retweet_count': [5,\n",
       "    1,\n",
       "    1065,\n",
       "    1,\n",
       "    0,\n",
       "    11,\n",
       "    27,\n",
       "    1407,\n",
       "    728,\n",
       "    1107,\n",
       "    0,\n",
       "    83014,\n",
       "    757,\n",
       "    1,\n",
       "    111312,\n",
       "    98,\n",
       "    2,\n",
       "    0,\n",
       "    5,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    14,\n",
       "    0,\n",
       "    0,\n",
       "    12,\n",
       "    46762,\n",
       "    19455,\n",
       "    1260,\n",
       "    3,\n",
       "    0,\n",
       "    4,\n",
       "    146,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    20,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    0,\n",
       "    2,\n",
       "    12522,\n",
       "    3,\n",
       "    0,\n",
       "    28,\n",
       "    12,\n",
       "    1183,\n",
       "    0,\n",
       "    3847,\n",
       "    21354,\n",
       "    1,\n",
       "    168,\n",
       "    352,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    984,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    18,\n",
       "    0,\n",
       "    0,\n",
       "    990,\n",
       "    0,\n",
       "    14,\n",
       "    0,\n",
       "    16,\n",
       "    1767,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    6,\n",
       "    5,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1151,\n",
       "    0,\n",
       "    1,\n",
       "    2,\n",
       "    18,\n",
       "    8,\n",
       "    169,\n",
       "    0,\n",
       "    0,\n",
       "    127,\n",
       "    7,\n",
       "    2,\n",
       "    4,\n",
       "    0,\n",
       "    59,\n",
       "    0,\n",
       "    3532,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    2091,\n",
       "    4,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    7,\n",
       "    1,\n",
       "    0,\n",
       "    4,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    2,\n",
       "    44244,\n",
       "    39,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    8,\n",
       "    44,\n",
       "    20,\n",
       "    1,\n",
       "    0,\n",
       "    267,\n",
       "    720,\n",
       "    0,\n",
       "    281,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    125,\n",
       "    2,\n",
       "    20075,\n",
       "    32683,\n",
       "    93,\n",
       "    571,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    27,\n",
       "    877,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    6,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    58829,\n",
       "    0,\n",
       "    5,\n",
       "    16,\n",
       "    0,\n",
       "    10,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    19,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    40,\n",
       "    72562,\n",
       "    7,\n",
       "    99,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    3,\n",
       "    22,\n",
       "    1645,\n",
       "    13,\n",
       "    14,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    6,\n",
       "    62,\n",
       "    0,\n",
       "    148,\n",
       "    0,\n",
       "    13,\n",
       "    811,\n",
       "    201,\n",
       "    588,\n",
       "    0,\n",
       "    8,\n",
       "    4,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    7,\n",
       "    2,\n",
       "    264,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1539,\n",
       "    20403,\n",
       "    313,\n",
       "    716,\n",
       "    614,\n",
       "    120,\n",
       "    692,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    17,\n",
       "    0,\n",
       "    0,\n",
       "    203,\n",
       "    73,\n",
       "    574,\n",
       "    20,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    19112,\n",
       "    97,\n",
       "    85403,\n",
       "    0,\n",
       "    67,\n",
       "    2,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    72,\n",
       "    0,\n",
       "    0,\n",
       "    194,\n",
       "    37,\n",
       "    381,\n",
       "    302,\n",
       "    7170,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    23,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    3555,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    4,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    1,\n",
       "    0,\n",
       "    7,\n",
       "    266,\n",
       "    615,\n",
       "    0,\n",
       "    0,\n",
       "    30,\n",
       "    0,\n",
       "    0,\n",
       "    27,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    365,\n",
       "    78,\n",
       "    35,\n",
       "    67,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    8,\n",
       "    6484,\n",
       "    8477,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    18718,\n",
       "    18899,\n",
       "    9,\n",
       "    293,\n",
       "    29,\n",
       "    2235,\n",
       "    4374,\n",
       "    21,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    362,\n",
       "    0,\n",
       "    0,\n",
       "    6,\n",
       "    0,\n",
       "    0,\n",
       "    172,\n",
       "    3776,\n",
       "    7,\n",
       "    3,\n",
       "    10,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    2,\n",
       "    2,\n",
       "    0,\n",
       "    4,\n",
       "    1,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    31,\n",
       "    1,\n",
       "    4,\n",
       "    10,\n",
       "    2,\n",
       "    7,\n",
       "    0,\n",
       "    1130,\n",
       "    0,\n",
       "    13,\n",
       "    1,\n",
       "    1,\n",
       "    2,\n",
       "    1,\n",
       "    6,\n",
       "    14,\n",
       "    0,\n",
       "    0,\n",
       "    20,\n",
       "    4,\n",
       "    2,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    853,\n",
       "    107,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1598,\n",
       "    232,\n",
       "    10,\n",
       "    323,\n",
       "    7,\n",
       "    129,\n",
       "    141,\n",
       "    0,\n",
       "    16665,\n",
       "    411,\n",
       "    2610,\n",
       "    28,\n",
       "    232,\n",
       "    209,\n",
       "    35,\n",
       "    0,\n",
       "    117,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    5,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    3559,\n",
       "    58,\n",
       "    136,\n",
       "    0,\n",
       "    0,\n",
       "    63,\n",
       "    4,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    526,\n",
       "    0,\n",
       "    3,\n",
       "    64,\n",
       "    3,\n",
       "    384,\n",
       "    15,\n",
       "    0,\n",
       "    15057,\n",
       "    0,\n",
       "    0,\n",
       "    24897,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    3,\n",
       "    167,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    21,\n",
       "    376,\n",
       "    4296,\n",
       "    0,\n",
       "    58,\n",
       "    0,\n",
       "    2,\n",
       "    348,\n",
       "    115,\n",
       "    1,\n",
       "    8,\n",
       "    0,\n",
       "    5,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    48,\n",
       "    125,\n",
       "    36,\n",
       "    5,\n",
       "    0,\n",
       "    265,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1077,\n",
       "    1540,\n",
       "    0,\n",
       "    3,\n",
       "    9935,\n",
       "    4137,\n",
       "    109,\n",
       "    3179,\n",
       "    642,\n",
       "    0,\n",
       "    193,\n",
       "    1034,\n",
       "    375,\n",
       "    95,\n",
       "    759,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    0,\n",
       "    1458,\n",
       "    1,\n",
       "    0,\n",
       "    84,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2049,\n",
       "    1201,\n",
       "    1288,\n",
       "    0,\n",
       "    115,\n",
       "    313,\n",
       "    419,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    55,\n",
       "    7,\n",
       "    585,\n",
       "    0,\n",
       "    327,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    14,\n",
       "    4,\n",
       "    205,\n",
       "    2424,\n",
       "    0,\n",
       "    1953,\n",
       "    44,\n",
       "    5,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    124,\n",
       "    5202,\n",
       "    0,\n",
       "    0,\n",
       "    4,\n",
       "    0,\n",
       "    14,\n",
       "    246,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    93,\n",
       "    1167,\n",
       "    5646,\n",
       "    3003,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    7,\n",
       "    85,\n",
       "    112,\n",
       "    0,\n",
       "    0,\n",
       "    1385,\n",
       "    169,\n",
       "    517,\n",
       "    0,\n",
       "    1279,\n",
       "    6,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    694,\n",
       "    200,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    8,\n",
       "    2,\n",
       "    10,\n",
       "    87,\n",
       "    4,\n",
       "    76646,\n",
       "    4753,\n",
       "    827,\n",
       "    0,\n",
       "    6,\n",
       "    10,\n",
       "    0,\n",
       "    10,\n",
       "    1033,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    14,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1752,\n",
       "    3,\n",
       "    0,\n",
       "    3,\n",
       "    13,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    8918,\n",
       "    6,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    233,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    8,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    63,\n",
       "    1667,\n",
       "    2189,\n",
       "    517,\n",
       "    23511,\n",
       "    0,\n",
       "    49,\n",
       "    28,\n",
       "    125,\n",
       "    112,\n",
       "    44,\n",
       "    16,\n",
       "    0,\n",
       "    0,\n",
       "    94,\n",
       "    70,\n",
       "    60,\n",
       "    10,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    149,\n",
       "    226,\n",
       "    9593,\n",
       "    21,\n",
       "    304,\n",
       "    3168,\n",
       "    504,\n",
       "    372,\n",
       "    14,\n",
       "    246,\n",
       "    241,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    5,\n",
       "    0,\n",
       "    1863,\n",
       "    823,\n",
       "    3205,\n",
       "    235,\n",
       "    184,\n",
       "    74,\n",
       "    61162,\n",
       "    7084,\n",
       "    1198,\n",
       "    981,\n",
       "    24680,\n",
       "    244,\n",
       "    1161,\n",
       "    49,\n",
       "    1113,\n",
       "    4962,\n",
       "    829,\n",
       "    0,\n",
       "    7302,\n",
       "    1206,\n",
       "    20184,\n",
       "    10328,\n",
       "    793,\n",
       "    112493,\n",
       "    6635,\n",
       "    6871,\n",
       "    0,\n",
       "    0,\n",
       "    201,\n",
       "    9515,\n",
       "    3295,\n",
       "    348,\n",
       "    523,\n",
       "    2519,\n",
       "    47861,\n",
       "    29748,\n",
       "    129,\n",
       "    579,\n",
       "    50237,\n",
       "    11,\n",
       "    1332,\n",
       "    18,\n",
       "    399,\n",
       "    23926,\n",
       "    5396,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    48,\n",
       "    229,\n",
       "    2,\n",
       "    142,\n",
       "    263442,\n",
       "    146,\n",
       "    2554,\n",
       "    13240,\n",
       "    119,\n",
       "    15532,\n",
       "    2104,\n",
       "    0,\n",
       "    0,\n",
       "    1353,\n",
       "    2630,\n",
       "    57362,\n",
       "    0,\n",
       "    28,\n",
       "    197,\n",
       "    22009,\n",
       "    10,\n",
       "    553,\n",
       "    515,\n",
       "    394,\n",
       "    601,\n",
       "    11582,\n",
       "    3350,\n",
       "    95,\n",
       "    5445,\n",
       "    0,\n",
       "    65,\n",
       "    0,\n",
       "    24,\n",
       "    40775,\n",
       "    29,\n",
       "    4083,\n",
       "    90,\n",
       "    873,\n",
       "    3189,\n",
       "    383,\n",
       "    2689,\n",
       "    334,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    505,\n",
       "    8366,\n",
       "    11239,\n",
       "    4189,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    193909,\n",
       "    0,\n",
       "    5,\n",
       "    2072,\n",
       "    14,\n",
       "    1660,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    974,\n",
       "    235,\n",
       "    514,\n",
       "    990,\n",
       "    867,\n",
       "    95,\n",
       "    0,\n",
       "    0,\n",
       "    10934,\n",
       "    1492,\n",
       "    24,\n",
       "    0,\n",
       "    237,\n",
       "    57,\n",
       "    276,\n",
       "    292,\n",
       "    42,\n",
       "    7055,\n",
       "    1393,\n",
       "    311,\n",
       "    1776,\n",
       "    2532,\n",
       "    264,\n",
       "    446,\n",
       "    0,\n",
       "    542,\n",
       "    17,\n",
       "    130,\n",
       "    145,\n",
       "    726,\n",
       "    1575,\n",
       "    3,\n",
       "    237,\n",
       "    869,\n",
       "    108,\n",
       "    421,\n",
       "    0,\n",
       "    1014,\n",
       "    191,\n",
       "    1201,\n",
       "    0,\n",
       "    0,\n",
       "    14,\n",
       "    641,\n",
       "    500,\n",
       "    370,\n",
       "    1314,\n",
       "    27,\n",
       "    176,\n",
       "    165,\n",
       "    143,\n",
       "    856,\n",
       "    29,\n",
       "    2607,\n",
       "    190,\n",
       "    1170,\n",
       "    35,\n",
       "    991,\n",
       "    0,\n",
       "    0,\n",
       "    458,\n",
       "    0,\n",
       "    0,\n",
       "    62,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    267,\n",
       "    26,\n",
       "    155,\n",
       "    20,\n",
       "    2,\n",
       "    1486,\n",
       "    1190,\n",
       "    258,\n",
       "    66,\n",
       "    698,\n",
       "    1010,\n",
       "    0,\n",
       "    10,\n",
       "    195,\n",
       "    30,\n",
       "    0,\n",
       "    40201,\n",
       "    1465,\n",
       "    8023,\n",
       "    180,\n",
       "    1603,\n",
       "    427,\n",
       "    21,\n",
       "    20,\n",
       "    31,\n",
       "    0,\n",
       "    604,\n",
       "    349,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    81,\n",
       "    20,\n",
       "    536,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    16,\n",
       "    208,\n",
       "    456,\n",
       "    103,\n",
       "    39,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    416,\n",
       "    0,\n",
       "    50,\n",
       "    206,\n",
       "    0,\n",
       "    0,\n",
       "    135,\n",
       "    464,\n",
       "    1300,\n",
       "    189,\n",
       "    21,\n",
       "    3236,\n",
       "    0,\n",
       "    0,\n",
       "    2,\n",
       "    9,\n",
       "    171,\n",
       "    0,\n",
       "    89,\n",
       "    65,\n",
       "    0,\n",
       "    0,\n",
       "    78,\n",
       "    93,\n",
       "    22,\n",
       "    157,\n",
       "    1,\n",
       "    0,\n",
       "    12,\n",
       "    53,\n",
       "    0,\n",
       "    0,\n",
       "    37,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    10,\n",
       "    23,\n",
       "    724,\n",
       "    1803,\n",
       "    1988,\n",
       "    0,\n",
       "    0,\n",
       "    4542,\n",
       "    0,\n",
       "    0,\n",
       "    577,\n",
       "    0,\n",
       "    8364,\n",
       "    35,\n",
       "    0,\n",
       "    22,\n",
       "    0,\n",
       "    419,\n",
       "    1079,\n",
       "    3,\n",
       "    86,\n",
       "    0,\n",
       "    1115,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    ...]}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_gabr_tweets #this is a list of 1 dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: LDA Analysis\n",
    "\n",
    "Let's now move onto the LDA pre-processing stage and analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from collections import Counter\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gabr_tweets = clean_gabr_tweets[0]['gabr_ibrahim']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great turnout today hope able join us slides available link video webinar coming soon',\n",
       " 'ms capp student talks challenges value time',\n",
       " 'good news steve bannon gone bad news replaced sentient swastika right arm permanently',\n",
       " 'byyyeeeee',\n",
       " 'late night could possibly better']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabr_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now proceed to tokenize these tweets in addition to lemmatizing them! This will help improve the performance of our LDA model!\n",
    "\n",
    "I will utilise spacy for this process as it is a production grade NLP library that is exceptionally fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_tweets = []\n",
    "for tweet in gabr_tweets:\n",
    "    tokenized_tweet = nlp(tweet)\n",
    "    \n",
    "    tweet = \"\" # we want to keep each tweet seperate\n",
    "    \n",
    "    for token in tokenized_tweet:\n",
    "        if token.is_space:\n",
    "            continue\n",
    "        elif token.is_punct:\n",
    "            continue\n",
    "        elif token.is_stop:\n",
    "            continue\n",
    "        elif token.is_digit:\n",
    "            continue\n",
    "        elif len(token) == 1:\n",
    "            continue\n",
    "        elif len(token) == 2:\n",
    "            continue\n",
    "        else:\n",
    "            tweet += str(token.lemma_) + \" \" #creating lemmatized version of tweet\n",
    "        \n",
    "    tokenized_tweets.append(tweet)\n",
    "tokenized_tweets = list(map(str.strip, tokenized_tweets)) # strip whitespace\n",
    "tokenized_tweets = [x for x in tokenized_tweets if x != \"\"] # remove empty entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great turnout today hope able join slide available link video webinar come soon',\n",
       " 'capp student talk challenge value time',\n",
       " 'good news steve bannon go bad news replace sentient swastika right arm permanently',\n",
       " 'byyyeeeee',\n",
       " 'late night possibly better']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweets[:5] # you can see how this is different to the raw tweets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now add these tokenized tweets to our dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets[0]['gabr_ibrahim']['tokenized_tweets'] = tokenized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not turn the dictionary back into a dataframe, run it through the filtration function before re-casting the dataframe into a dictionary.\n",
    "\n",
    "This time, we are running the filtration process on the tokenized tweets column and not the content column.\n",
    "\n",
    "NLP models are very sensitive - ensuring consistent cleaning is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets_df = pd.DataFrame.from_dict(clean_gabr_tweets[0], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gabr_ibrahim</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[great turnout today hope able join us slides ...</td>\n",
       "      <td>[great turnout today hope able join slide avai...</td>\n",
       "      <td>[5, 1, 1065, 1, 0, 11, 27, 1407, 728, 1107, 0,...</td>\n",
       "      <td>[opendata, NLP, spaCy, Metis, TopicModelling, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 favorite_count  \\\n",
       "gabr_ibrahim  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                        content  \\\n",
       "gabr_ibrahim  [great turnout today hope able join us slides ...   \n",
       "\n",
       "                                               tokenized_tweets  \\\n",
       "gabr_ibrahim  [great turnout today hope able join slide avai...   \n",
       "\n",
       "                                                  retweet_count  \\\n",
       "gabr_ibrahim  [5, 1, 1065, 1, 0, 11, 27, 1407, 728, 1107, 0,...   \n",
       "\n",
       "                                                       hashtags  \n",
       "gabr_ibrahim  [opendata, NLP, spaCy, Metis, TopicModelling, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_gabr_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets_df = filtration(clean_gabr_tweets_df, \"tokenized_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets = dataframe_to_dict(clean_gabr_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great turnout today hope able join slide available link video webinar come soon',\n",
       " 'capp student talk challenge value time',\n",
       " 'good news steve bannon go bad news replace sentient swastika right arm permanently',\n",
       " 'byyyeeeee',\n",
       " 'late night possibly better']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_gabr_tweets[0]['gabr_ibrahim']['tokenized_tweets'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA Process\n",
    "\n",
    "Fantastic - at this point, we have everything we need to proceed with LDA from the Gensim Library.\n",
    "\n",
    "LDA via the Gensim library requires that our data be in a very specific format.\n",
    "\n",
    "Broadly, LDA requires a Dictionary object that is later used to create a matrix called a corpus.\n",
    "\n",
    "The Gensim LDA Dictionary will require that we pass in a list of lists. Every sublist will be a tweet that has been split.\n",
    "\n",
    "Let's look at my first tweet as an example.\n",
    "\n",
    "Before:\n",
    "\n",
    "['great turnout today hope able join slide available link video webinar come soon', tweet 2, tweet 3, ...]\n",
    "\n",
    "Correct Gensim Format:\n",
    "\n",
    "[['great', 'turnout', 'today', 'hope', 'able', 'join', 'slide', 'available','link', 'video', 'webinar', 'come', 'soon'], [tweet 2 in split form], [...],...]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_tweets_gabr = clean_gabr_tweets[0]['gabr_ibrahim']['tokenized_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_format_tweets = []\n",
    "for tweet in list_of_tweets_gabr:\n",
    "    list_form = tweet.split()\n",
    "    gensim_format_tweets.append(list_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['great',\n",
       "  'turnout',\n",
       "  'today',\n",
       "  'hope',\n",
       "  'able',\n",
       "  'join',\n",
       "  'slide',\n",
       "  'available',\n",
       "  'link',\n",
       "  'video',\n",
       "  'webinar',\n",
       "  'come',\n",
       "  'soon'],\n",
       " ['capp', 'student', 'talk', 'challenge', 'value', 'time'],\n",
       " ['good',\n",
       "  'news',\n",
       "  'steve',\n",
       "  'bannon',\n",
       "  'go',\n",
       "  'bad',\n",
       "  'news',\n",
       "  'replace',\n",
       "  'sentient',\n",
       "  'swastika',\n",
       "  'right',\n",
       "  'arm',\n",
       "  'permanently'],\n",
       " ['byyyeeeee'],\n",
       " ['late', 'night', 'possibly', 'better']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_format_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_dictionary = Dictionary(gensim_format_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, I will now filter out extreme words - that is words that appear far too often and words that are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "gensim_dictionary.compactify() # remove gaps after words that were removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to voctorize all the tweets so that it can be fed to the LDA algorithm! To do this, we will create a bag of words model from our tweets.\n",
    "\n",
    "After putting all our tweets through this bag of words model, we will end up with a 'corpus' that represents all the tweets for a particular user. In this case, that user is myself.\n",
    "\n",
    "We will save this corpus to disk as we go along! We will use the MmCorpus object from Gensim to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/igabr/new-project-4\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_corpus = \"/home/igabr/new-project-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words_generator(lst, dictionary):\n",
    "    assert type(dictionary) == Dictionary, \"Please enter a Gensim Dictionary\"\n",
    "    for i in lst: \n",
    "        yield dictionary.doc2bow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MmCorpus.serialize(file_path_corpus+\"{}.mm\".format(\"gabr_ibrahim\"), bag_of_words_generator(gensim_format_tweets, gensim_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = MmCorpus(file_path_corpus+\"{}.mm\".format(\"gabr_ibrahim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.num_terms # the number of terms in our corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.num_docs # the number of documets. These are the number of tweets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for the LDA part!\n",
    "\n",
    "I will be using the LDAMulticore class from gensim!\n",
    "\n",
    "I set the passess parameter to 100 and the chunksize to 2000.\n",
    "\n",
    "The chunksie will ensure it use's all the documents at once, and the passess parameter will ensure it looks at all the documents 100 times before converging.\n",
    "\n",
    "As I am using my ENTIRE tweet history, I will create 30 topics!\n",
    "\n",
    "I will adjust this to 10 when running lda on 2nd degree connections, as I will only have 200 of their tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus, num_topics=30, id2word=gensim_dictionary, chunksize=2000, workers=100, passes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then save this lda model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.save(file_path_corpus+\"lda_model_{}\".format(\"gabr_ibrahim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore.load(file_path_corpus+\"lda_model_{}\".format(\"gabr_ibrahim\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now wish to extract all of the words that appear in each of the 30 topics that the LDA model was able to create.\n",
    "\n",
    "For each word in a topic, I will ensure that it has a frequency not equal to 0.\n",
    "\n",
    "I will place all these words into a list and then wrap a Counter object around it!\n",
    "\n",
    "\n",
    "I am doing this as I want to see the distribution of words that appear accross all topics for a particular user. The LDA process will highlight key words that a particular user often uses in their twitter freed, across all topics that a particular user discusses. As such, the words they use will be indicitive of the topics a twitter user talks about!\n",
    "\n",
    "The counter object will simply keep a count of how many times, out of a maximum of 30 (topics) a word appears, given it has a frequency greater than 0. That is, the word appears in a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "for i in range(30):\n",
    "    for term, frequency in lda.show_topic(i, topn=100): #returns top 100 words for a topic\n",
    "        if frequency != 0:\n",
    "            word_list.append(term)\n",
    "temp = Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This can be done later to help filter the important words.\n",
    "important_words = []\n",
    "for k, v in temp.items():\n",
    "    if v >= 10:\n",
    "        if k not in nltk_stopwords:\n",
    "            doc = nlp(k)\n",
    "            \n",
    "            for token in doc:\n",
    "                if not token.is_stop:\n",
    "                    if len(token) != 2:\n",
    "                        important_words.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foreign',\n",
       " 'refugee',\n",
       " 'expert',\n",
       " 'age',\n",
       " 'russian',\n",
       " 'woman',\n",
       " 'clinton',\n",
       " 'syria',\n",
       " 'official',\n",
       " 'talk',\n",
       " 'share',\n",
       " 'court',\n",
       " 'london',\n",
       " 'security',\n",
       " 'turkey',\n",
       " 'military',\n",
       " 'ask',\n",
       " 'record',\n",
       " 'airport',\n",
       " 'year',\n",
       " 'find',\n",
       " 'coup',\n",
       " 'end',\n",
       " 'video',\n",
       " 'office',\n",
       " 'today',\n",
       " 'president',\n",
       " 'republican',\n",
       " 'know',\n",
       " 'blast',\n",
       " 'man',\n",
       " 'government',\n",
       " 'russia',\n",
       " 'british',\n",
       " 'political',\n",
       " 'free',\n",
       " 'week',\n",
       " 'important',\n",
       " 'work',\n",
       " 'plan',\n",
       " 'hillary',\n",
       " 'parliament',\n",
       " 'control',\n",
       " 'news',\n",
       " 'public',\n",
       " 'syrian',\n",
       " 'remember',\n",
       " 'late',\n",
       " 'second',\n",
       " 'student',\n",
       " 'tell',\n",
       " 'read',\n",
       " 'fuck',\n",
       " 'scotland',\n",
       " 'police',\n",
       " 'love',\n",
       " 'islamic',\n",
       " 'support',\n",
       " 'update',\n",
       " 'think',\n",
       " 'datum',\n",
       " 'policy',\n",
       " 'time',\n",
       " 'create',\n",
       " 'far',\n",
       " 'machine',\n",
       " 'hit',\n",
       " 'post',\n",
       " 'follow',\n",
       " 'cnn',\n",
       " 'order',\n",
       " 'come',\n",
       " 'new',\n",
       " 'open',\n",
       " 'country',\n",
       " 'change',\n",
       " 'good',\n",
       " 'right',\n",
       " 'night',\n",
       " 'die',\n",
       " 'national',\n",
       " 'confirm',\n",
       " 'turnout',\n",
       " 'isis',\n",
       " 'medium',\n",
       " 'live',\n",
       " 'long',\n",
       " 'tax',\n",
       " 'issue',\n",
       " 'hostage',\n",
       " 'stop',\n",
       " 'ankara',\n",
       " 'like',\n",
       " 'future',\n",
       " 'leave',\n",
       " 'force',\n",
       " 'staff',\n",
       " 'house',\n",
       " 'thing',\n",
       " 'people',\n",
       " 'white',\n",
       " 'law',\n",
       " 'air',\n",
       " 'turkish',\n",
       " 'muslim',\n",
       " 'help',\n",
       " 'break',\n",
       " 'result',\n",
       " 'school',\n",
       " 'hold',\n",
       " 'strike',\n",
       " 'sign',\n",
       " 'fire',\n",
       " 'shoot',\n",
       " 'state',\n",
       " 'number',\n",
       " 'vote',\n",
       " 'way',\n",
       " 'trump',\n",
       " 'try',\n",
       " 'minister',\n",
       " 'kill',\n",
       " 'israeli',\n",
       " 'party',\n",
       " 'referendum',\n",
       " 'start',\n",
       " 'iraq',\n",
       " 'accord',\n",
       " 'blog',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'drop',\n",
       " 'watch',\n",
       " 'attack',\n",
       " 'job',\n",
       " 'attempt',\n",
       " 'leader',\n",
       " 'david',\n",
       " 'debate',\n",
       " 'day',\n",
       " 'thank',\n",
       " 'poll',\n",
       " 'run',\n",
       " 'incredible',\n",
       " 'grad',\n",
       " 'cameron',\n",
       " 'claim',\n",
       " 'fall',\n",
       " 'let',\n",
       " 'presidential',\n",
       " 'join',\n",
       " 'great',\n",
       " 'hear',\n",
       " 'life',\n",
       " 'big',\n",
       " 'bomb',\n",
       " 'lead',\n",
       " 'want',\n",
       " 'look',\n",
       " 'election',\n",
       " 'donald',\n",
       " 'capital',\n",
       " 'obama',\n",
       " 'use',\n",
       " 'question',\n",
       " 'near',\n",
       " 'source',\n",
       " 'world',\n",
       " 'war',\n",
       " 'report',\n",
       " 'science',\n",
       " 'mean',\n",
       " 'team',\n",
       " 'close',\n",
       " 'american',\n",
       " 'yes',\n",
       " 'check',\n",
       " 'city',\n",
       " 'east',\n",
       " 'remain',\n",
       " 'learn',\n",
       " 'win']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will then place this LDA Counter Object back into our dictionary!\n",
    "\n",
    "We will then pickle this object - we will use it again for our TF-IDF analysis!\n",
    "\n",
    "Be sure to look at the file called lda.py to see how I stuructured the code to run through the 2nd degree connections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['favorite_count', 'content', 'hashtags', 'retweet_count', 'tokenized_tweets'])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_gabr_tweets[0]['gabr_ibrahim'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_gabr_tweets[0]['gabr_ibrahim']['LDA'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_object(clean_gabr_tweets, \"gabr_ibrahim_tweets_LDA_Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
